{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d6020ca-531b-4c7f-a533-c8507b5cadec",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92ebccfa-017f-4658-bd84-bd4242c3f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f37ae-2ab1-49ae-8f9e-48be02192c72",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6294c3-ebef-4ba8-85c8-db0b5115d222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>...</th>\n",
       "      <th>r_offense_date</th>\n",
       "      <th>r_charge_desc</th>\n",
       "      <th>r_jail_in</th>\n",
       "      <th>r_jail_out</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>num_vr_cases</th>\n",
       "      <th>vr_case_number</th>\n",
       "      <th>vr_charge_degree</th>\n",
       "      <th>vr_offense_date</th>\n",
       "      <th>vr_charge_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>1947-04-18 00:00:00.000000</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>michael ryan</td>\n",
       "      <td>michael</td>\n",
       "      <td>ryan</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1985-02-06 00:00:00.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1982-01-22 00:00:00.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-07-05 00:00:00.000000</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13009779CF10A</td>\n",
       "      <td>(F3)</td>\n",
       "      <td>2013-07-05 00:00:00.000000</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1991-05-14 00:00:00.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-06-16 00:00:00.000000</td>\n",
       "      <td>Driving Under The Influence</td>\n",
       "      <td>2013-06-16 09:05:47.000000</td>\n",
       "      <td>2013-06-16 07:18:55.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1993-01-21 00:00:00.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11752</th>\n",
       "      <td>11753</td>\n",
       "      <td>patrick hamilton</td>\n",
       "      <td>patrick</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>1968-05-02 00:00:00.000000</td>\n",
       "      <td>47</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11753</th>\n",
       "      <td>11754</td>\n",
       "      <td>raymond hernandez</td>\n",
       "      <td>raymond</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1993-06-24 00:00:00.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-11 00:00:00.000000</td>\n",
       "      <td>Driving License Suspended</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11754</th>\n",
       "      <td>11755</td>\n",
       "      <td>dieuseul pierre-gilles</td>\n",
       "      <td>dieuseul</td>\n",
       "      <td>pierre-gilles</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>1981-01-24 00:00:00.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11755</th>\n",
       "      <td>11756</td>\n",
       "      <td>scott lomagistro</td>\n",
       "      <td>scott</td>\n",
       "      <td>lomagistro</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1986-12-04 00:00:00.000000</td>\n",
       "      <td>29</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11756</th>\n",
       "      <td>11757</td>\n",
       "      <td>chin yan</td>\n",
       "      <td>chin</td>\n",
       "      <td>yan</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>1982-02-19 00:00:00.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11757 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                    name     first           last   sex  \\\n",
       "0          1        miguel hernandez    miguel      hernandez  Male   \n",
       "1          2            michael ryan   michael           ryan  Male   \n",
       "2          3             kevon dixon     kevon          dixon  Male   \n",
       "3          4                ed philo        ed          philo  Male   \n",
       "4          5             marcu brown     marcu          brown  Male   \n",
       "...      ...                     ...       ...            ...   ...   \n",
       "11752  11753        patrick hamilton   patrick       hamilton  Male   \n",
       "11753  11754       raymond hernandez   raymond      hernandez  Male   \n",
       "11754  11755  dieuseul pierre-gilles  dieuseul  pierre-gilles  Male   \n",
       "11755  11756        scott lomagistro     scott     lomagistro  Male   \n",
       "11756  11757                chin yan      chin            yan  Male   \n",
       "\n",
       "                   race                         dob  age          age_cat  \\\n",
       "0                 Other  1947-04-18 00:00:00.000000   69  Greater than 45   \n",
       "1             Caucasian  1985-02-06 00:00:00.000000   31          25 - 45   \n",
       "2      African-American  1982-01-22 00:00:00.000000   34          25 - 45   \n",
       "3      African-American  1991-05-14 00:00:00.000000   24     Less than 25   \n",
       "4      African-American  1993-01-21 00:00:00.000000   23     Less than 25   \n",
       "...                 ...                         ...  ...              ...   \n",
       "11752             Other  1968-05-02 00:00:00.000000   47  Greater than 45   \n",
       "11753         Caucasian  1993-06-24 00:00:00.000000   22     Less than 25   \n",
       "11754             Other  1981-01-24 00:00:00.000000   35          25 - 45   \n",
       "11755         Caucasian  1986-12-04 00:00:00.000000   29          25 - 45   \n",
       "11756             Asian  1982-02-19 00:00:00.000000   34          25 - 45   \n",
       "\n",
       "       juv_fel_count  ...              r_offense_date  \\\n",
       "0                  0  ...                         NaN   \n",
       "1                  0  ...                         NaN   \n",
       "2                  0  ...  2013-07-05 00:00:00.000000   \n",
       "3                  0  ...  2013-06-16 00:00:00.000000   \n",
       "4                  0  ...                         NaN   \n",
       "...              ...  ...                         ...   \n",
       "11752              0  ...                         NaN   \n",
       "11753              0  ...  2014-10-11 00:00:00.000000   \n",
       "11754              0  ...                         NaN   \n",
       "11755              0  ...                         NaN   \n",
       "11756              0  ...                         NaN   \n",
       "\n",
       "                     r_charge_desc                   r_jail_in  \\\n",
       "0                              NaN                         NaN   \n",
       "1                              NaN                         NaN   \n",
       "2      Felony Battery (Dom Strang)                         NaN   \n",
       "3      Driving Under The Influence  2013-06-16 09:05:47.000000   \n",
       "4                              NaN                         NaN   \n",
       "...                            ...                         ...   \n",
       "11752                          NaN                         NaN   \n",
       "11753    Driving License Suspended                         NaN   \n",
       "11754                          NaN                         NaN   \n",
       "11755                          NaN                         NaN   \n",
       "11756                          NaN                         NaN   \n",
       "\n",
       "                       r_jail_out  is_violent_recid  num_vr_cases  \\\n",
       "0                             NaN                 0           NaN   \n",
       "1                             NaN                 0           NaN   \n",
       "2                             NaN                 1           NaN   \n",
       "3      2013-06-16 07:18:55.000000                 0           NaN   \n",
       "4                             NaN                 0           NaN   \n",
       "...                           ...               ...           ...   \n",
       "11752                         NaN                 0           NaN   \n",
       "11753                         NaN                 0           NaN   \n",
       "11754                         NaN                 0           NaN   \n",
       "11755                         NaN                 0           NaN   \n",
       "11756                         NaN                 0           NaN   \n",
       "\n",
       "       vr_case_number  vr_charge_degree             vr_offense_date  \\\n",
       "0                 NaN               NaN                         NaN   \n",
       "1                 NaN               NaN                         NaN   \n",
       "2       13009779CF10A              (F3)  2013-07-05 00:00:00.000000   \n",
       "3                 NaN               NaN                         NaN   \n",
       "4                 NaN               NaN                         NaN   \n",
       "...               ...               ...                         ...   \n",
       "11752             NaN               NaN                         NaN   \n",
       "11753             NaN               NaN                         NaN   \n",
       "11754             NaN               NaN                         NaN   \n",
       "11755             NaN               NaN                         NaN   \n",
       "11756             NaN               NaN                         NaN   \n",
       "\n",
       "                    vr_charge_desc  \n",
       "0                              NaN  \n",
       "1                              NaN  \n",
       "2      Felony Battery (Dom Strang)  \n",
       "3                              NaN  \n",
       "4                              NaN  \n",
       "...                            ...  \n",
       "11752                          NaN  \n",
       "11753                          NaN  \n",
       "11754                          NaN  \n",
       "11755                          NaN  \n",
       "11756                          NaN  \n",
       "\n",
       "[11757 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('compas_people.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58d09ea-af50-446d-bd22-d00e6962356d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11757 entries, 0 to 11756\n",
      "Data columns (total 41 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       11757 non-null  int64  \n",
      " 1   name                     11757 non-null  object \n",
      " 2   first                    11757 non-null  object \n",
      " 3   last                     11757 non-null  object \n",
      " 4   sex                      11757 non-null  object \n",
      " 5   race                     11757 non-null  object \n",
      " 6   dob                      11757 non-null  object \n",
      " 7   age                      11757 non-null  int64  \n",
      " 8   age_cat                  11757 non-null  object \n",
      " 9   juv_fel_count            11757 non-null  int64  \n",
      " 10  juv_misd_count           11757 non-null  int64  \n",
      " 11  juv_other_count          11757 non-null  int64  \n",
      " 12  compas_screening_date    11757 non-null  object \n",
      " 13  decile_score             11757 non-null  int64  \n",
      " 14  score_text               0 non-null      float64\n",
      " 15  violent_recid            0 non-null      float64\n",
      " 16  priors_count             11757 non-null  int64  \n",
      " 17  days_b_screening_arrest  10577 non-null  float64\n",
      " 18  c_jail_in                10577 non-null  object \n",
      " 19  c_jail_out               10577 non-null  object \n",
      " 20  c_case_number            11015 non-null  object \n",
      " 21  c_days_from_compas       11015 non-null  float64\n",
      " 22  c_arrest_date            1858 non-null   object \n",
      " 23  c_offense_date           9157 non-null   object \n",
      " 24  c_charge_degree          11015 non-null  object \n",
      " 25  c_charge_desc            11008 non-null  object \n",
      " 26  is_recid                 11757 non-null  int64  \n",
      " 27  num_r_cases              3703 non-null   float64\n",
      " 28  r_case_number            3703 non-null   object \n",
      " 29  r_charge_degree          3703 non-null   object \n",
      " 30  r_days_from_arrest       2460 non-null   float64\n",
      " 31  r_offense_date           3703 non-null   object \n",
      " 32  r_charge_desc            3643 non-null   object \n",
      " 33  r_jail_in                2460 non-null   object \n",
      " 34  r_jail_out               2460 non-null   object \n",
      " 35  is_violent_recid         11757 non-null  int64  \n",
      " 36  num_vr_cases             0 non-null      float64\n",
      " 37  vr_case_number           882 non-null    object \n",
      " 38  vr_charge_degree         882 non-null    object \n",
      " 39  vr_offense_date          882 non-null    object \n",
      " 40  vr_charge_desc           882 non-null    object \n",
      "dtypes: float64(7), int64(9), object(25)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd9b89-4815-4b14-829c-3eecc140ff75",
   "metadata": {},
   "source": [
    "Okay, not too bad. We're gonna get rid of a lot of categories, though: mostly ones that assume that recidivism has already happened along with some that are unique, like `name` and `c_case_number`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f3a6580-5084-4211-ab6b-69edf42b0391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['name', 'first', 'last', \n",
    "              'score_text', 'violent_recid', 'c_case_number', \n",
    "              'c_offense_date', 'c_charge_desc', 'r_case_number', \n",
    "              'r_charge_degree', 'r_days_from_arrest', 'r_offense_date', \n",
    "              'r_charge_desc', 'r_jail_in', 'r_jail_out', \n",
    "              'is_violent_recid', 'num_vr_cases', 'vr_case_number', \n",
    "              'vr_charge_degree', 'vr_offense_date', 'vr_charge_desc',\n",
    "              'c_arrest_date', 'dob', 'days_b_screening_arrest',\n",
    "              'c_days_from_compas', 'id', 'compas_screening_date',\n",
    "              'num_r_cases'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c440bb3f-5184-4ada-a7aa-9edf31058d93",
   "metadata": {},
   "source": [
    "Next we're gonna consolidate `jail-in` and `jail-out` to `jail-time` so we only have to deal with a duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b85707-3e00-4695-83e8-75b279421a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['jail_time'] = (pd.to_datetime(df.c_jail_out) - pd.to_datetime(df.c_jail_in)).astype(\"timedelta64[s]\")\n",
    "df.jail_time.fillna(0, inplace=True)\n",
    "df.drop(['c_jail_in', 'c_jail_out'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942cedd2-4810-4869-812e-fe08d945dece",
   "metadata": {},
   "source": [
    "Okay, so, there's a couple different charge degrees missing values - we're gonna fill those in with the most common value for that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4720a08e-d953-4442-b7a6-1afc0289ee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(F3)     5913\n",
       "(M1)     2831\n",
       "(F2)      953\n",
       "(M2)      857\n",
       "(F1)      221\n",
       "(F7)      128\n",
       "(MO3)      83\n",
       "(F6)       10\n",
       "(NI0)       8\n",
       "(F5)        7\n",
       "(X)         1\n",
       "(CT)        1\n",
       "(TCX)       1\n",
       "(CO3)       1\n",
       "Name: c_charge_degree, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c_charge_degree.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82cabd40-52e1-4f4b-a8a3-88a1de94e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.c_charge_degree.fillna('(F3)', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f5f11c-2ad2-440e-8364-cf7fc95234c7",
   "metadata": {},
   "source": [
    "There's a number of entries that have a recidivism score of -1 - unfortunately, without a usable truth value, those entries aren't useful to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fb32008-bcc9-4c37-ae30-25deb449b073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.is_recid != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50290bd-e81f-4862-bcc9-25de7600a5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11038 entries, 0 to 11756\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   sex              11038 non-null  object \n",
      " 1   race             11038 non-null  object \n",
      " 2   age              11038 non-null  int64  \n",
      " 3   age_cat          11038 non-null  object \n",
      " 4   juv_fel_count    11038 non-null  int64  \n",
      " 5   juv_misd_count   11038 non-null  int64  \n",
      " 6   juv_other_count  11038 non-null  int64  \n",
      " 7   decile_score     11038 non-null  int64  \n",
      " 8   priors_count     11038 non-null  int64  \n",
      " 9   c_charge_degree  11038 non-null  object \n",
      " 10  is_recid         11038 non-null  int64  \n",
      " 11  jail_time        11038 non-null  float64\n",
      "dtypes: float64(1), int64(7), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195770f9-7fc5-46c0-bab0-d1765f4825c4",
   "metadata": {},
   "source": [
    "Much better. Now we're gonna split off the data that needs to be scaled and the data that needs to be encoded into a one-hot, do those transformations, then put them back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aee13d95-b909-4529-86bc-fc97e9ea9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "needs_scaling = df.drop(['sex', 'race', 'age_cat', 'c_charge_degree', 'is_recid'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(needs_scaling)\n",
    "\n",
    "needs_encoding = df[['sex', 'race', 'age_cat', 'c_charge_degree']]\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "one_hot_data = enc.fit_transform(needs_encoding)\n",
    "\n",
    "transformed_data = np.concatenate((scaled_data, one_hot_data), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78931c5-7b89-46cb-91af-da0b3edb58c5",
   "metadata": {},
   "source": [
    "This next bit is pretty straightforward: split the data into train/test/validation sets. The only slightly unusual thing we're going to do is to create new DataFrames to store the train/test/validation data so that we can come back and do some analysis at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "554313cd-9d67-4662-9cb5-a918907c5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['is_recid'].values\n",
    "x = transformed_data\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3)\n",
    "\n",
    "train_df = pd.DataFrame([])\n",
    "combo_df = pd.DataFrame([])\n",
    "test_df = pd.DataFrame([])\n",
    "valid_df = pd.DataFrame([])\n",
    "\n",
    "for train_index, combo_index in sss.split(x, y):\n",
    "    train_x, combo_x = x[train_index], x[combo_index]\n",
    "    train_y, combo_y = y[train_index], y[combo_index]\n",
    "    train_df = train_df.append(df.iloc[train_index])\n",
    "    combo_df = combo_df.append(df.iloc[combo_index])\n",
    "    \n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5)\n",
    "\n",
    "for test_index, valid_index in sss.split(combo_x, combo_y):\n",
    "    test_x, valid_x = combo_x[test_index], combo_x[valid_index]\n",
    "    test_y, valid_y = combo_y[test_index], combo_y[valid_index]\n",
    "    test_df = test_df.append(combo_df.iloc[test_index])\n",
    "    valid_df = valid_df.append(combo_df.iloc[valid_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c517cae4-065c-4d69-afc2-a6a2d330c914",
   "metadata": {},
   "source": [
    "Last but not least we define a couple helper methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33cf556c-ddc5-4a49-b2de-4bae37a5b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = {'acc': 0}\n",
    "\n",
    "# Tracks model with highest accuracy\n",
    "def update_best_model(acc, name, model, params):\n",
    "    if (acc > best_model['acc']):\n",
    "        best_model['acc'] = acc\n",
    "        best_model['name'] = name\n",
    "        best_model['model'] = model\n",
    "        best_model['params'] = params\n",
    "\n",
    "# Performs a grid search on a passed-in classifier\n",
    "def run_grid_search(folds, params, clf, name):\n",
    "    gscv = GridSearchCV(clf, params, cv=folds)\n",
    "    gscv.fit(train_x, train_y)\n",
    "    acc = accuracy_score(test_y, gscv.predict(test_x))\n",
    "    update_best_model(acc, name, gscv, gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a366b8a5-ce48-4173-aae9-55a4d7896351",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Algorithm Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a0cfcf-1909-484c-a571-d2920d05fb24",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we're gonna perform a grid search on several different algorithms: KNN, Decision Trees, Random Forest, Logistic Regression, and DNN. The accuracy score for each algorithm will be compared against each other and the model with the highest accuracy will be retained so we can test it against the validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e9233-a157-4051-ab21-8ecdeeab933c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95bb2ea5-a899-4f5c-b282-adee73bca232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = 10\n",
    "params = {'n_neighbors': list(range(3, 16))}\n",
    "\n",
    "run_grid_search(folds, params, KNeighborsClassifier(), 'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b3f43e-56f4-4956-807e-88a5512e445b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33131d1e-5dc7-4a04-9c87-1469740af6b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d85c222c-55ae-4547-8aef-4e13724ba342",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 10\n",
    "params = {'criterion': ('entropy', 'gini'),\n",
    "         'max_depth': [2, 3, 4, 5, 6, 7, 8]}\n",
    "\n",
    "run_grid_search(folds, params, DecisionTreeClassifier(), 'Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266f795-5146-4af2-9ca6-1dba388af3a3",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ca55806-6c4f-464a-82c2-7f191d34c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 10\n",
    "params = {'criterion': ('entropy', 'gini'),\n",
    "         'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
    "         'n_estimators': [10, 20, 30, 40]}\n",
    "\n",
    "run_grid_search(folds, params, RandomForestClassifier(), 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f389b7c2-6ab1-43b1-b38a-d67cfce5a9e2",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2f41001-ec07-420d-b2a1-d9c977d1bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 10\n",
    "params = {'penalty': ['l1', 'l2'],\n",
    "             'C': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "run_grid_search(folds, params, LogisticRegression(solver='liblinear'), 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0fad3c-1b7f-45e6-ba4d-2f8700b7fdc1",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb4fcdc-1d1d-47d3-bebf-5724f1a416be",
   "metadata": {},
   "source": [
    "WARNING: \n",
    "- Running the following code locally will write run logs to your machine \n",
    "- These files *do not* overwrite themselves. Run `!rm -rf ./logs` to delete old runs.\n",
    "- The `--logdir` argument for Tensorboard doesn't work great - this is a known issue. Instead of navigating to the provided directory, Tensorboard will (at least, on Windows) display all the logs in the first folder it finds (using a top-down search) that has logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a79cbaaf-0fb8-44a1-95d8-83232e80b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = tf.dtypes.cast(train_x, tf.float64)\n",
    "test_x = tf.dtypes.cast(test_x, tf.float64)\n",
    "valid_x = tf.dtypes.cast(valid_x, tf.float64)\n",
    "\n",
    "train_y = tf.dtypes.cast(train_y, tf.int64)\n",
    "test_y = tf.dtypes.cast(test_y, tf.int64)\n",
    "valid_y = tf.dtypes.cast(valid_y, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "488ccdee-6545-486b-b656-89bf4359f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c71277a-4742-4da1-92d3-175a8aa6a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([40, 80, 120]))\n",
    "HP_NUM_LAYERS = hp.HParam('num_layers', hp.Discrete([1, 2, 3]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', 'rmsprop']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_NUM_LAYERS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d4c4c2-04b9-440e-be5e-ec5e9f076833",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- Adding loss weights doesn't really affect accuracy but *can* massively decrease loss, for some reason. [0.2, 3] reduces loss from ~0.5 all the way down to 0.1-0.12 range\n",
    "- Deriving the loss weights from the dataset itself doesn't seem to make much of a difference\n",
    "- Messing around with the loss function doesn't really do much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8879d49-0cab-4029-a426-114e8dff2890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "\n",
    "  model = tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "  for i in range(hparams[HP_NUM_LAYERS]):\n",
    "        model.add(tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu))\n",
    "        \n",
    "  model.add(tf.keras.layers.Dropout(hparams[HP_DROPOUT]))\n",
    "  model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "#       loss_weights=[0.2,3],\n",
    "  )\n",
    "    \n",
    "  model.fit(train_x, train_y, epochs=20) \n",
    "  _, accuracy = model.evaluate(test_x, test_y)\n",
    "    \n",
    "  update_best_model(accuracy, 'DNN', model, hparams)\n",
    "\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bb924f7-c844-49ca-8f2e-a6acdf1135f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)\n",
    "    accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "425c8717-05fd-42e4-af7c-8ff6b79c8e0e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6130 - accuracy: 0.6648\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5837 - accuracy: 0.6935\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.7013\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.7039\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.7077\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5692 - accuracy: 0.7093\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7114\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.7083\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7092\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.7097\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.7133\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5631 - accuracy: 0.7089\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.7138\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.7116\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.7149\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5612 - accuracy: 0.7124\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.7119\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.7140\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.7127\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7154\n",
      "52/52 [==============================] - 0s 739us/step - loss: 0.5627 - accuracy: 0.7089\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5990 - accuracy: 0.6798\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5769 - accuracy: 0.7000\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.7040\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.7053\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.7097\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7121\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5626 - accuracy: 0.7057\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.7147\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7145\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5586 - accuracy: 0.7133\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5573 - accuracy: 0.7209\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5555 - accuracy: 0.7180\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.7198\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7196\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 0.7199\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5514 - accuracy: 0.7203\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5503 - accuracy: 0.7224\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5488 - accuracy: 0.7256\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.7264\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5479 - accuracy: 0.7208\n",
      "52/52 [==============================] - 0s 783us/step - loss: 0.5702 - accuracy: 0.7114\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5986 - accuracy: 0.6859\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5757 - accuracy: 0.7039\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7022\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.7046\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.7106\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5639 - accuracy: 0.7094\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7108\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7083\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5581 - accuracy: 0.7118\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7154\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5551 - accuracy: 0.7138\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.7173\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7187\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5512 - accuracy: 0.7212\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5478 - accuracy: 0.7216\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5460 - accuracy: 0.7206\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5457 - accuracy: 0.7240\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.7273\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 0.7248\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5389 - accuracy: 0.7278\n",
      "52/52 [==============================] - 0s 737us/step - loss: 0.5792 - accuracy: 0.6957\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5956 - accuracy: 0.6874\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5799 - accuracy: 0.7004\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.7045\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5722 - accuracy: 0.7030: 0s - loss: 0.5581 - accura\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7046\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.5707 - accuracy: 0.7039\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.5686 - accuracy: 0.7026\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.5688 - accuracy: 0.7071\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.5663 - accuracy: 0.7058\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7075\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7080\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.5636 - accuracy: 0.7071\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.5639 - accuracy: 0.7076\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.5635 - accuracy: 0.7106\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5631 - accuracy: 0.7097\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5615 - accuracy: 0.7149\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.7112\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5621 - accuracy: 0.7115\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.7088\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5600 - accuracy: 0.7124\n",
      "52/52 [==============================] - 0s 667us/step - loss: 0.5662 - accuracy: 0.7041\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5934 - accuracy: 0.6945\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.5761 - accuracy: 0.70 - 0s 1ms/step - loss: 0.5775 - accuracy: 0.7000\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.7037\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.7075\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7097\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.7111\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7120\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7133\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7138\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5588 - accuracy: 0.7164\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7142\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5586 - accuracy: 0.7155\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.7174\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5553 - accuracy: 0.7195\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5540 - accuracy: 0.7215\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5529 - accuracy: 0.7196\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5537 - accuracy: 0.7178\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.7224\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 0.7208\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5523 - accuracy: 0.7213\n",
      "52/52 [==============================] - 0s 721us/step - loss: 0.5705 - accuracy: 0.7114\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5873 - accuracy: 0.6859\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.7009\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7072\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.7083\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7127\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5621 - accuracy: 0.7141\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5615 - accuracy: 0.7145\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7186\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7196\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.7140\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7171\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5539 - accuracy: 0.7198\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.7198\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5503 - accuracy: 0.7228\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5485 - accuracy: 0.7218\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5503 - accuracy: 0.7230\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.7268\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7260\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5444 - accuracy: 0.7294\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5439 - accuracy: 0.7268\n",
      "52/52 [==============================] - 0s 706us/step - loss: 0.5750 - accuracy: 0.7029\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6174 - accuracy: 0.6688\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5930 - accuracy: 0.6899\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5876 - accuracy: 0.6913\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5851 - accuracy: 0.6908\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.5833 - accuracy: 0.6917\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.6974: 0s - loss: 0.5785 - accuracy: 0.69\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5787 - accuracy: 0.6991\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.5790 - accuracy: 0.6979\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.6979\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.5788 - accuracy: 0.6963\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5773 - accuracy: 0.7006\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.7015\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.6992\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5746 - accuracy: 0.7017\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5750 - accuracy: 0.6980\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.7019\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.7011\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5712 - accuracy: 0.7039\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7032\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5719 - accuracy: 0.7039\n",
      "52/52 [==============================] - 0s 725us/step - loss: 0.5647 - accuracy: 0.7059\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6253 - accuracy: 0.6498\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5916 - accuracy: 0.6953\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.7015\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5825 - accuracy: 0.6987\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.6980\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.6993\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.6995\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.6998\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.7008\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5719 - accuracy: 0.7074\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7061\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7035\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.7009\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.7058\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.7058\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7046\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.7046\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.7071\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.7042\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.7071\n",
      "52/52 [==============================] - 0s 712us/step - loss: 0.5652 - accuracy: 0.7132\n",
      "--- Starting trial: run-8\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6473 - accuracy: 0.6534\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6122 - accuracy: 0.6732\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5976 - accuracy: 0.6807\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5884 - accuracy: 0.6905\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5814 - accuracy: 0.6974\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5814 - accuracy: 0.6979\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5787 - accuracy: 0.7018\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.7041\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.6997\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5751 - accuracy: 0.7039\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.7028\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.7031\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.7046\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5737 - accuracy: 0.7017\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7067\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5718 - accuracy: 0.7017\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7052\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.7052\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.7052\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7070\n",
      "52/52 [==============================] - 0s 719us/step - loss: 0.5667 - accuracy: 0.7120\n",
      "--- Starting trial: run-9\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6053 - accuracy: 0.6851\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5828 - accuracy: 0.6903\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.7000\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.7041\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.7058\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.7077\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5692 - accuracy: 0.7094\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.7058\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7054\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.7079\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7085\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7096\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7077\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7059\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.7079\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7077\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7119\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7099\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7130\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5626 - accuracy: 0.7124\n",
      "52/52 [==============================] - 0s 706us/step - loss: 0.5615 - accuracy: 0.7101\n",
      "--- Starting trial: run-10\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.6809\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7023\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7042\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7086\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7076\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7080\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7125\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7098\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7114\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.7149\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5612 - accuracy: 0.7125\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5589 - accuracy: 0.7163\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7130\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5578 - accuracy: 0.7196\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5568 - accuracy: 0.7198: 0s - loss: 0.5369 - accura\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.7204\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5553 - accuracy: 0.7185\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 0.7167\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5539 - accuracy: 0.7169\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5506 - accuracy: 0.7206\n",
      "52/52 [==============================] - 0s 745us/step - loss: 0.5649 - accuracy: 0.7089\n",
      "--- Starting trial: run-11\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6035 - accuracy: 0.6802\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.5790 - accuracy: 0.69 - 0s 1ms/step - loss: 0.5789 - accuracy: 0.6982\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7037\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.7066\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7112\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5627 - accuracy: 0.7103\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.7114\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.7141: 0s - loss: 0.5533 - accu\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5599 - accuracy: 0.7147\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.7151\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5539 - accuracy: 0.7167\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5530 - accuracy: 0.7180\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5524 - accuracy: 0.7147\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5510 - accuracy: 0.7199\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.7237\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.7225: 0s - loss: 0.5496 - accuracy: 0.72\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5453 - accuracy: 0.7266\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7231\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.7279\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7286\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5772 - accuracy: 0.7065\n",
      "--- Starting trial: run-12\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6155 - accuracy: 0.6723\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5873 - accuracy: 0.6975\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.6922\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7008\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7044\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.6997\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7045\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.7064\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7053\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.7072\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5701 - accuracy: 0.7063\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.7066\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5687 - accuracy: 0.7112\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.7090\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7110\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.7089\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7115\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7110\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7098\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7136\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5650 - accuracy: 0.7059\n",
      "--- Starting trial: run-13\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5982 - accuracy: 0.6824\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.6988\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5736 - accuracy: 0.7071\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.7052\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5716 - accuracy: 0.7094\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.7118\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7105\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7140\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7108\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7156\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7173\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7158\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7158\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7195\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7191\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.7174\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.7203\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7198\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7269\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7204\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7059\n",
      "--- Starting trial: run-14\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6013 - accuracy: 0.6835\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.6965\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7089\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7071\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7094\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7107\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7121\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7137\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7154\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5580 - accuracy: 0.7163\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7152\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7196\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7195\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7194\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7244\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7229\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7256\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7250\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7274\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7251\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.7011\n",
      "--- Starting trial: run-15\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6690 - accuracy: 0.6325\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.6719\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.6864\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5899 - accuracy: 0.6847\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.6896\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.6952\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5830 - accuracy: 0.6940\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5847 - accuracy: 0.6954\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.6987\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5795 - accuracy: 0.6962\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.6961\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5773 - accuracy: 0.6986\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.7001\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5777 - accuracy: 0.6988\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.7027\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5757 - accuracy: 0.7027\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.7028\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.7030\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5745 - accuracy: 0.7046\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.7039\n",
      "52/52 [==============================] - 0s 784us/step - loss: 0.5655 - accuracy: 0.7071\n",
      "--- Starting trial: run-16\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6222 - accuracy: 0.6670\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5940 - accuracy: 0.6860\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5870 - accuracy: 0.6892\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5870 - accuracy: 0.6931\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5851 - accuracy: 0.6908\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.6923\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.6936\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.6966\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5767 - accuracy: 0.6969\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.7020\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.6996\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5769 - accuracy: 0.6979\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.7011\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.7002\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.7022\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5739 - accuracy: 0.6996\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7014\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7026\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7052\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5722 - accuracy: 0.7068\n",
      "52/52 [==============================] - 0s 843us/step - loss: 0.5675 - accuracy: 0.7053\n",
      "--- Starting trial: run-17\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6379 - accuracy: 0.6561\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.6829\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5908 - accuracy: 0.6901\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5845 - accuracy: 0.6974\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5825 - accuracy: 0.6954\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.6966\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.7013\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5778 - accuracy: 0.6997\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.6986\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5745 - accuracy: 0.7053\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.7059\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7031\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.7035\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5743 - accuracy: 0.7050\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7061\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7046\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7092\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.7074\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.7052\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7124\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5631 - accuracy: 0.7101\n",
      "--- Starting trial: run-18\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6021 - accuracy: 0.6816\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.6993\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7080\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7053\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7070\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.7127\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7118\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7141\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7103\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7138\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5586 - accuracy: 0.7138\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7167\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7178\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7160\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5568 - accuracy: 0.7162\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7173\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7182\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5558 - accuracy: 0.7221\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5538 - accuracy: 0.7220\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7216\n",
      "52/52 [==============================] - 0s 882us/step - loss: 0.5661 - accuracy: 0.7065\n",
      "--- Starting trial: run-19\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5874 - accuracy: 0.6948\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7066\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7080\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7088\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7114\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7116\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7142\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7141\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7142\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7182\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5537 - accuracy: 0.7173\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5517 - accuracy: 0.7147\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7181\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7216\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5461 - accuracy: 0.7233\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7274\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7279\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7286\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7287\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7325\n",
      "52/52 [==============================] - 0s 824us/step - loss: 0.5816 - accuracy: 0.7017\n",
      "--- Starting trial: run-20\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5873 - accuracy: 0.6897\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7080\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7079\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7124\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7088\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7154\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7141\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7189\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7191\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7230\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7272\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7242\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7284\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7294\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7345\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7357\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5271 - accuracy: 0.7405\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7373\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7432\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7424\n",
      "52/52 [==============================] - 0s 902us/step - loss: 0.6046 - accuracy: 0.6987\n",
      "--- Starting trial: run-21\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5882 - accuracy: 0.6919\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.7057\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7054\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7070\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7049\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7089\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7098\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7112\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7121\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7125\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7120\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5618 - accuracy: 0.7134\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7143\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5625 - accuracy: 0.7146\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5616 - accuracy: 0.7125: 0s - loss: 0.5616 - accuracy: 0.\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5600 - accuracy: 0.7169\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5599 - accuracy: 0.7125\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5603 - accuracy: 0.7128: 0s - loss: 0.5537 - accu\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5601 - accuracy: 0.7147\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5587 - accuracy: 0.7143\n",
      "52/52 [==============================] - 0s 885us/step - loss: 0.5639 - accuracy: 0.7114\n",
      "--- Starting trial: run-22\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.5886 - accuracy: 0.69 - 1s 3ms/step - loss: 0.5862 - accuracy: 0.6931\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5731 - accuracy: 0.7062\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5698 - accuracy: 0.7066\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5648 - accuracy: 0.7108\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7115\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.7099\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7149\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7182\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7156\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.7176\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5556 - accuracy: 0.7165\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.7204\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5530 - accuracy: 0.7215\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5510 - accuracy: 0.7268\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5498 - accuracy: 0.7221\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5461 - accuracy: 0.7239\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5466 - accuracy: 0.7246\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5435 - accuracy: 0.7237\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5438 - accuracy: 0.7283\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5441 - accuracy: 0.7301\n",
      "52/52 [==============================] - 0s 682us/step - loss: 0.5804 - accuracy: 0.7059\n",
      "--- Starting trial: run-23\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5870 - accuracy: 0.6963\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.7052\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.7071\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.7084\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7115\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7162\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5580 - accuracy: 0.7172\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5561 - accuracy: 0.7141\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5539 - accuracy: 0.7173\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7215\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5496 - accuracy: 0.7243\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5464 - accuracy: 0.7283\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7303\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.7323\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.7338\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.7362\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5349 - accuracy: 0.7358\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.7375\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5322 - accuracy: 0.7361\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.7388\n",
      "52/52 [==============================] - 0s 765us/step - loss: 0.6127 - accuracy: 0.7071\n",
      "--- Starting trial: run-24\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.6221 - accuracy: 0.6632\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.5894 - accuracy: 0.6899\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.5855 - accuracy: 0.6960\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.6947\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.5794 - accuracy: 0.6995\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.5783 - accuracy: 0.6979\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.5757 - accuracy: 0.6991\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.5762 - accuracy: 0.7023\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.5736 - accuracy: 0.70 - 0s 975us/step - loss: 0.5748 - accuracy: 0.7008\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5745 - accuracy: 0.7040\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5745 - accuracy: 0.7014\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5739 - accuracy: 0.7002\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.7027\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.5704 - accuracy: 0.7062\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.5701 - accuracy: 0.7054\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.5703 - accuracy: 0.7044\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.5707 - accuracy: 0.7059\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.5702 - accuracy: 0.7037\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7063\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7046\n",
      "52/52 [==============================] - 0s 765us/step - loss: 0.5639 - accuracy: 0.7065\n",
      "--- Starting trial: run-25\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6179 - accuracy: 0.6676\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5853 - accuracy: 0.6903\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5824 - accuracy: 0.6978\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.5794 - accuracy: 0.7015\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.7033\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5756 - accuracy: 0.7040\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.7037\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.5721 - accuracy: 0.7052\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5720 - accuracy: 0.7048\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.5710 - accuracy: 0.7046\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.7114\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.5709 - accuracy: 0.7093\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7090\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.5693 - accuracy: 0.7083\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7077\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.5692 - accuracy: 0.7068\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7110\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.5673 - accuracy: 0.7133\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7107\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.7081\n",
      "52/52 [==============================] - 0s 708us/step - loss: 0.5630 - accuracy: 0.7132\n",
      "--- Starting trial: run-26\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6415 - accuracy: 0.6356\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5989 - accuracy: 0.6819\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5897 - accuracy: 0.6914\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5845 - accuracy: 0.6944\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5806 - accuracy: 0.7009\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5795 - accuracy: 0.7020\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.7010\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7018\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.7024\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.7061\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.7068\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.5703 - accuracy: 0.7064\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7097\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5701 - accuracy: 0.7101\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7062\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.7090\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.7128: 0s - loss: 0.5552 - accuracy: \n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7114\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5650 - accuracy: 0.7127\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.7121\n",
      "52/52 [==============================] - ETA: 4s - loss: 0.5003 - accuracy: 0.75 - 0s 737us/step - loss: 0.5657 - accuracy: 0.7138\n",
      "--- Starting trial: run-27\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6051 - accuracy: 0.6758\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5790 - accuracy: 0.6996\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5761 - accuracy: 0.7031\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.5716 - accuracy: 0.7030\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7062\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7077\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.5675 - accuracy: 0.7094\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7083\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.7052\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.7106\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7106\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7112\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5626 - accuracy: 0.7103\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.7142\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5604 - accuracy: 0.7119\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7164\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7127\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5577 - accuracy: 0.7158\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7185\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5571 - accuracy: 0.7138\n",
      "52/52 [==============================] - 0s 687us/step - loss: 0.5672 - accuracy: 0.7132\n",
      "--- Starting trial: run-28\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5901 - accuracy: 0.6863\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.7030: 0s - loss: 0.5832 - accuracy: \n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7086\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.7105\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.7096\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7141\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5577 - accuracy: 0.7132\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.7174\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7182\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7198\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.7198\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5500 - accuracy: 0.7260\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.7237\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5474 - accuracy: 0.7164\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5469 - accuracy: 0.7274\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7238\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.7260\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7294\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5401 - accuracy: 0.7274\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5384 - accuracy: 0.7286\n",
      "52/52 [==============================] - 0s 765us/step - loss: 0.5740 - accuracy: 0.7083\n",
      "--- Starting trial: run-29\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5865 - accuracy: 0.6886: 0s - loss: 0.5869 - accuracy: 0.68\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7037\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7061\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7110\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5605 - accuracy: 0.7128\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7154\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.7165\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7182\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7174\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7216\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5455 - accuracy: 0.7237\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5444 - accuracy: 0.7228\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7251\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5387 - accuracy: 0.7291\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.7343\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.7335\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5282 - accuracy: 0.7339\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5262 - accuracy: 0.7400\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7378\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7423\n",
      "52/52 [==============================] - 0s 804us/step - loss: 0.5957 - accuracy: 0.6981\n",
      "--- Starting trial: run-30\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6045 - accuracy: 0.6834\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.7014\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5769 - accuracy: 0.7031\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5746 - accuracy: 0.7032\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7005\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.7049\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.7039\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7042\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7119\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5651 - accuracy: 0.7079\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7061\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.7099\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5636 - accuracy: 0.7128\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7090\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5636 - accuracy: 0.7128\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7102\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7123\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7114\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7125\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7093\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.7126\n",
      "--- Starting trial: run-31\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5901 - accuracy: 0.6919\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.7031\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.7090\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7071\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7083\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7149\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7111\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7145\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7162\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.7125\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5558 - accuracy: 0.7213\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7178\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7174\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7240\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7204\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7297\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7238\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7256\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7253\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7281\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.5834 - accuracy: 0.7089\n",
      "--- Starting trial: run-32\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5901 - accuracy: 0.6843\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7005\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7030\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7077\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7138\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7105\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7098\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7162\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7185\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7178\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7217\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5497 - accuracy: 0.7225\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7257\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7250\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7281\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7336\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7295\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7325\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7344\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7366\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.6013 - accuracy: 0.6963\n",
      "--- Starting trial: run-33\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6435 - accuracy: 0.6303\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5974 - accuracy: 0.6847\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5915 - accuracy: 0.6957\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5879 - accuracy: 0.6860\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5867 - accuracy: 0.6951\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5851 - accuracy: 0.6930\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5820 - accuracy: 0.7000\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5812 - accuracy: 0.6982\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.6978\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.7033\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.7019\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5773 - accuracy: 0.7006\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5753 - accuracy: 0.7020\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.7023\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5753 - accuracy: 0.7040\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5766 - accuracy: 0.7006\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5750 - accuracy: 0.7020\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.7055\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5746 - accuracy: 0.7020\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.7031\n",
      "52/52 [==============================] - 0s 882us/step - loss: 0.5634 - accuracy: 0.7089\n",
      "--- Starting trial: run-34\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6233 - accuracy: 0.6564\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5888 - accuracy: 0.6919\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5852 - accuracy: 0.6963\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5809 - accuracy: 0.7005\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5803 - accuracy: 0.7014\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.7009\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5790 - accuracy: 0.6991\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7055\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5750 - accuracy: 0.7024\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.7024\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.7061\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5730 - accuracy: 0.7018\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.7050\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7083\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5716 - accuracy: 0.7048\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5701 - accuracy: 0.7075\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7099\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.7097\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.7079\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.7068\n",
      "52/52 [==============================] - 0s 765us/step - loss: 0.5639 - accuracy: 0.7035\n",
      "--- Starting trial: run-35\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6432 - accuracy: 0.6351\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6013 - accuracy: 0.6776\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.6948\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5845 - accuracy: 0.6987\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.6987\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7004\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.7042\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.7015\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5753 - accuracy: 0.7017\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.7052\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.7072\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.7064\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7083\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5701 - accuracy: 0.7055\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7059\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7050\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7071\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7080\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7090\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7105\n",
      "52/52 [==============================] - 0s 1000us/step - loss: 0.5649 - accuracy: 0.7083\n",
      "--- Starting trial: run-36\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5892 - accuracy: 0.6917\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5730 - accuracy: 0.7054\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7059\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.7049\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7055\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5639 - accuracy: 0.7106\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7147\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.7132\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.7149\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5582 - accuracy: 0.7132\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 0.7137\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7146\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.7150\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5551 - accuracy: 0.7185\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.7193\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7215\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.7206\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5524 - accuracy: 0.7189\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5516 - accuracy: 0.7220\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.7228\n",
      "52/52 [==============================] - 0s 726us/step - loss: 0.5723 - accuracy: 0.7023\n",
      "--- Starting trial: run-37\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5865 - accuracy: 0.6945\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7028\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.7090\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7105\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7097\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.7180\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5571 - accuracy: 0.7152\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7171\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.7203\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7222\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7243\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7238\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7246\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5432 - accuracy: 0.7239\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7301\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.7322\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7300\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7371\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - accuracy: 0.7393\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5279 - accuracy: 0.7392\n",
      "52/52 [==============================] - 0s 765us/step - loss: 0.5896 - accuracy: 0.7029\n",
      "--- Starting trial: run-38\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5835 - accuracy: 0.6948\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7044\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7090\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7130\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7118\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7141\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7169\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7226\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7228\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7208\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7246\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7292\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7310\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7369\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7371\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7429\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7436\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7446\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7512\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7515\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.6153 - accuracy: 0.6932\n",
      "--- Starting trial: run-39\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5882 - accuracy: 0.6914\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.7036\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7064\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.7055\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.7062\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7081\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5639 - accuracy: 0.7083: 0s - loss: 0.5636 - accuracy: \n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7102\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.7116\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.7159\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7116\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.7159\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5578 - accuracy: 0.7143\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5570 - accuracy: 0.7136\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5562 - accuracy: 0.7163\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7147\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5548 - accuracy: 0.7194\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5540 - accuracy: 0.7171\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5561 - accuracy: 0.7167\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.7181\n",
      "52/52 [==============================] - 0s 785us/step - loss: 0.5680 - accuracy: 0.7029\n",
      "--- Starting trial: run-40\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5859 - accuracy: 0.6936\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5736 - accuracy: 0.7026\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.7071\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.7136\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.7116\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.7169\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.7180: 0s - loss: 0.5589 - accuracy\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5557 - accuracy: 0.7194\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5561 - accuracy: 0.7180\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.7216\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7242: 0s - loss: 0.5509 - accuracy: 0.\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7237\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7265\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5460 - accuracy: 0.7252\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7294\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7304\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7310\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5364 - accuracy: 0.7348\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.7331\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.7334\n",
      "52/52 [==============================] - 0s 804us/step - loss: 0.5849 - accuracy: 0.6914\n",
      "--- Starting trial: run-41\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5837 - accuracy: 0.6940\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5719 - accuracy: 0.7059\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7077\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7127\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7154\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.7162\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7165\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5558 - accuracy: 0.7169\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5533 - accuracy: 0.7217\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5529 - accuracy: 0.7224\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.7242\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5456 - accuracy: 0.7304\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 0.7323\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5440 - accuracy: 0.7308\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.7353\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.7389\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5339 - accuracy: 0.7378\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5281 - accuracy: 0.7413\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.7441\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5257 - accuracy: 0.7429\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.6040 - accuracy: 0.6993\n",
      "--- Starting trial: run-42\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6027 - accuracy: 0.6878\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.6987\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.6973\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.7039\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5794 - accuracy: 0.6997\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.7061\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.7027\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.7063\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.7052\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.7075\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.7050\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5703 - accuracy: 0.7084: 0s - loss: 0.5674 - accuracy: 0.\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7089\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7055\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7112\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7058\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5701 - accuracy: 0.7064\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.7064\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7083\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7096\n",
      "52/52 [==============================] - 0s 765us/step - loss: 0.5637 - accuracy: 0.7132\n",
      "--- Starting trial: run-43\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6058 - accuracy: 0.6771\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.6900\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.6970\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5770 - accuracy: 0.7020\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7032\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5736 - accuracy: 0.7036\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.7083\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.7077\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.7057\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5703 - accuracy: 0.7074\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.7063\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7090\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7099\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7105\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.7115\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7106\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7118\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.7112\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7107\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7121\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7041\n",
      "--- Starting trial: run-44\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6172 - accuracy: 0.6623\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5861 - accuracy: 0.6910\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.7009\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.7006\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.7006\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.7062\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7046\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7083\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7041\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7076\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7064\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7079\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7103\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.7111\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7086\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5626 - accuracy: 0.7086: 0s - loss: 0.5624 - accuracy: 0.\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7079\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7123\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5611 - accuracy: 0.7106\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5608 - accuracy: 0.7115\n",
      "52/52 [==============================] - 0s 784us/step - loss: 0.5668 - accuracy: 0.7071\n",
      "--- Starting trial: run-45\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6017 - accuracy: 0.6855\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5790 - accuracy: 0.6996\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.7070\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7023\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7090\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.7030\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.7075\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.7066\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.7090\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5615 - accuracy: 0.7080\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.7136\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.7134\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7172\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5564 - accuracy: 0.7134\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.7177\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5589 - accuracy: 0.7137\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.7171\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.7177\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.7194\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5538 - accuracy: 0.7185\n",
      "52/52 [==============================] - 0s 843us/step - loss: 0.5651 - accuracy: 0.7077\n",
      "--- Starting trial: run-46\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5865 - accuracy: 0.6956\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7049\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7080\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7066\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7112\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7125\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7094\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7152\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7196\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7193\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7177\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7204\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7186\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7260\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7266\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7286\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7278\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7283\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7306\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7363\n",
      "52/52 [==============================] - 0s 863us/step - loss: 0.5874 - accuracy: 0.7041\n",
      "--- Starting trial: run-47\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5866 - accuracy: 0.6958\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7052\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7103\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7075\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7120\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7121\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7147\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7172\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7204\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7228\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7217\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7287\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7295\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7303\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7353\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7351\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7407\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7422\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7494\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7481\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6160 - accuracy: 0.7077\n",
      "--- Starting trial: run-48\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5950 - accuracy: 0.6882\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.7023\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.6997\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.7002\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7059\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7058\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7070\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.7088\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.7094\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.7079\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5639 - accuracy: 0.7108\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7118\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5622 - accuracy: 0.7106\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7108\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7106\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.7121\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7106\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.7134\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7159\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5580 - accuracy: 0.7180\n",
      "52/52 [==============================] - 0s 863us/step - loss: 0.5672 - accuracy: 0.7059\n",
      "--- Starting trial: run-49\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5884 - accuracy: 0.6890\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7036\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7059\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7112\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7063\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.7112\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7136\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7177\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7171\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7149\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7231\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7209\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7244\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7213\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5486 - accuracy: 0.7240\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7279\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5439 - accuracy: 0.7278\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.7294\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5422 - accuracy: 0.7308\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.7300\n",
      "52/52 [==============================] - 0s 863us/step - loss: 0.5814 - accuracy: 0.7035\n",
      "--- Starting trial: run-50\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5881 - accuracy: 0.6904\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7086\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.7098\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7114\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7107\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7105\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7156\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7150\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7206\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7229\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7222\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7259\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7308\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7331\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7334\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7373\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7402\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7423\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7444\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7446\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6203 - accuracy: 0.7029\n",
      "--- Starting trial: run-51\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6166 - accuracy: 0.6650\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.6922\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5861 - accuracy: 0.6919\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5844 - accuracy: 0.6969\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.6952\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7000\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7044\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5783 - accuracy: 0.7008\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.6983\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.7010\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.7022\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.7064\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5743 - accuracy: 0.7028\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5730 - accuracy: 0.7018\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5737 - accuracy: 0.7052\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5736 - accuracy: 0.7066\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.7052\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5719 - accuracy: 0.7062\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.7050\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.7040\n",
      "52/52 [==============================] - 0s 784us/step - loss: 0.5624 - accuracy: 0.7168\n",
      "--- Starting trial: run-52\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6199 - accuracy: 0.6680\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5908 - accuracy: 0.6896\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5852 - accuracy: 0.6975\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5817 - accuracy: 0.6987\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5794 - accuracy: 0.6983\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7008\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.7028\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.7067\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.7057\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.7042\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5718 - accuracy: 0.7050\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.7070\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7052\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.7089\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7050\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7074\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7106\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7083\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7072\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5651 - accuracy: 0.7086\n",
      "52/52 [==============================] - 0s 823us/step - loss: 0.5643 - accuracy: 0.7029\n",
      "--- Starting trial: run-53\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6245 - accuracy: 0.6503\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.6886\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6953\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.7005\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.7009\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5737 - accuracy: 0.7057\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5730 - accuracy: 0.7058\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.7044\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5687 - accuracy: 0.7106\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.7116\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7068\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7049\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7088\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7081\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.71 - 0s 1ms/step - loss: 0.5644 - accuracy: 0.7090\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5644 - accuracy: 0.7094\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7092\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7068\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5644 - accuracy: 0.7079\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7124\n",
      "52/52 [==============================] - 0s 883us/step - loss: 0.5651 - accuracy: 0.7089\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "        for num_layers in HP_NUM_LAYERS.domain.values:\n",
    "          hparams = {\n",
    "              HP_NUM_UNITS: num_units,\n",
    "              HP_DROPOUT: dropout_rate,\n",
    "              HP_OPTIMIZER: optimizer,\n",
    "              HP_NUM_LAYERS: num_layers,\n",
    "          }\n",
    "          run_name = \"run-%d\" % session_num\n",
    "          print('--- Starting trial: %s' % run_name)\n",
    "          print({h.name: hparams[h] for h in hparams})\n",
    "          run('logs/hparam_tuning/' + run_name, hparams)\n",
    "          session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "984bce2b-7b61-4066-9606-385dca9e2c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13816), started 3 days, 1:22:01 ago. (Use '!kill 13816' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6ae1534795ea9b3e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6ae1534795ea9b3e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning --host localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c2c2d-1bbf-4bde-b29c-45dfd41cea5d",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23360e4f-3c0a-4f73-84e2-d68e399a613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: DNN \n",
      "Accuracy: 0.7167874574661255\n",
      "Parameters: dict_values([120, 0.2, 'sgd', 1])\n"
     ]
    }
   ],
   "source": [
    "print('Best Model:', best_model['name'], '\\nAccuracy:', best_model['acc']) \n",
    "\n",
    "if (best_model['name'] == 'DNN'):\n",
    "    print('Parameters:', best_model['params'].values())\n",
    "else:\n",
    "    print('Parameters:', best_model['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f4b58-610e-4b36-92ea-3157658ce38e",
   "metadata": {},
   "source": [
    "Now, let's test our best model against our validation set and see how it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09da2559-41a9-4e72-a63c-d54680084cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 745us/step - loss: 0.5662 - accuracy: 0.7144\n",
      "Accuracy of best model on validation set: 0.7143719792366028\n"
     ]
    }
   ],
   "source": [
    "prediction = best_model['model'].predict(valid_x)\n",
    "if (best_model['name'] == 'DNN'):\n",
    "    prediction = np.argmax(prediction, axis=1)\n",
    "    _, valid_acc = best_model['model'].evaluate(valid_x, valid_y)\n",
    "else:\n",
    "    valid_acc = accuracy_score(valid_y, prediction)\n",
    "\n",
    "print(\"Accuracy of best model on validation set:\", valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ecffa-b377-48ac-9725-98ffe6c7984b",
   "metadata": {},
   "source": [
    "## Racism Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa634536-41cf-4cbf-9809-b19e9b1cc6b0",
   "metadata": {},
   "source": [
    "Last but not least, let's check out how racist our model is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3bb29c4-f06d-4d07-892d-8151ecb51f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to get different sets of data based on recidivism value\n",
    "def get_diff_dict(column):\n",
    "    predict_df = valid_df.copy(deep=True)   \n",
    "    predict_df[column] = prediction\n",
    "\n",
    "    yes_predict_df = predict_df[predict_df[column] == 1]\n",
    "    yes_valid_df = valid_df[valid_df[column] == 1]\n",
    "\n",
    "    no_predict_df = predict_df[predict_df[column] == 0]\n",
    "    no_valid_df = valid_df[valid_df[column] == 0]\n",
    "\n",
    "    return {'Validation Set': valid_df, 'Prediction Set': predict_df,\n",
    "              'Validation where Recidivism=True': yes_valid_df, 'Prediction where Recidivism=True': yes_predict_df,\n",
    "              'Validation where Recidivism=False': no_valid_df, 'Prediction where Recidivism=False': no_predict_df}\n",
    "    \n",
    "    \n",
    "diff_dict = get_diff_dict('is_recid')\n",
    "diff_values = list(diff_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26174e06-05d8-4519-8632-04a1ccf49ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAANzCAYAAAC09LldAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAB8K0lEQVR4nOzdeZglZXn38e/PGfZlCItkRGSMooiCo6CRKMYtRkFfXIiIGCGJ8qLJa2JiEjTG4Bo0MRKjCeK+g1FUlKgogjvLDKugiMoojgiiYZNFHO/3j3oaaprTM90zNXO6Z76f6zpX1/rUXed0133uqqeqU1VIkiRJktbe3cYdgCRJkiRtKCywJEmSJGkgFliSJEmSNBALLEmSJEkaiAWWJEmSJA3EAkuSJEmSBmKBJc0hSSrJfdvw8Un+cTrLrsF2Dkty2prGKUnSVJK8N8lr2/D+SS5bw3ZWmQelcbHAktajJJ9L8uoR0w9K8tMk86fbVlUdVVWvGSCmRa0Yu2PbVfWhqnri2rY9xfZenuSKJDcl+XGSk6a53hFJvrYuYpIkrSzJsiS3tGP11a0o2nro7VTVV6vq/tOI5y45YKg8OGJb2yV5d8vLNyb5bpKjp7nuHcWjNl4WWNL69T7guUkyafofAx+qql+PIab1JsnhdPv6hKraGtgXOH28UUmSpvDUdqx+KN3x+hWTF5jJicE55M3A1sADgAXA/wG+N9aINKdYYEnr1yeBHYD9JyYk+S3gKcD7kzw8yTeTXJfkqiRvTbLpqIYmnyVL8rdtnZ8k+dNJyx6Y5PwkNyS5MskxvdlfaT+va2cq95t8pjDJ7yU5N8n17efv9eadmeQ1Sb7ezvSdlmTHKfb/YcDnq+r7AFX106o6odfWgiTvavuxPMlrk8xL8gDgeGC/FuN1U77DkqRBVdVy4LPAg+COLuh/nuRy4PI27SlJLmj56xtJ9p5YP8lDkpzXcsRJwOa9eY9J8uPe+K5JTk7ysyQ/b3lwZA4YkQdfkOR7SX6R5JQk9+jNqyRHJbm8xfi2ESc7JzwM+HBV/W9V/aaqvlNVH+u1tUeSL7TtXJbkWW36kcBhwN+1OD+9hm+55jgLLGk9qqpbgI8Cz+tNfhbwnaq6EFgBvATYEdgPeDzwotW1m+RJwEuBPwB2B54waZFftm1uBxwIvDDJ09q8R7ef21XV1lX1zUltbw+cCryFrjj8N+DUJDv0FnsO8CfA3YFNWyyjnAU8rxWD+yaZN2n+e4FfA/cFHgI8EXh+VX0bOAr4ZotxuynfDEnSoJLsChwAnN+b/DTgd4E9kzwEeDfwf+nyxNuBU5Js1k4SfhL4ALA98N/AM6fYzjzgM8APgUXALsCJ08kBSR4H/DNdTl3Y2jhx0mJPoSue9m7L/eEUu3wW8Lokf5Jk90nb2Qr4AvBhupz3bOA/k+zZThh+CHhji/OpU7SvDZwFlrT+vQ84OMnEGbzntWlU1dKqOquqfl1Vy+iS1O9Po81nAe+pqm9V1S+BY/ozq+rMqrq4nYm7CPjINNuFriC7vKo+0OL6CPAdoJ843lNV3+0VkItHNVRVHwT+H11S+zJwTZK/B0iyM10C/6uq+mVVXUPXTePZ04xTkjSsT7arRV+jO2a/vjfvn6vqF+24fyTw9qo6u6pWVNX7gNuAR7TXJsBxVXV7uxJ07hTbezhwD+BvWx64taqme+/tYcC7q+q8qroNeBndFa9FvWWOrarrqupHwBlMkavo8tSHgL8ALm1XxZ7c5j0FWFZV72k58Xzg48AfTTNObQQ2xH6z0qxWVV9Lci3wtCTn0iWUZwAkuR/dFaJ9gS3p/kaXTqPZe0xa7of9mUl+FziWrnvHpsBmdGcRp+Mek9tr47v0xn/aG76Zru/6SFX1IeBDSTahOwP6oSQXAP9Ll4Sv6vXauBtw5TTjlCQN62lV9cUp5vWPzbsBhyf5f71pm9LljwKWV1X15k3OKRN2BX64hvcj3wM4b2Kkqm5K8nO6XLWsTZ5WrmpF4+uB1yfZFjga+O8k96Lb19+d1FV9Pt0VOgnwCpY0Lu+nu3L1XLp7kq5u0/+L7urQ7lW1LfByYKo+4n1X0SWmCfeaNP/DwCnArlW1gK4v+0S7xar9hC6h9N0LWD6NuKbUzmT+N3ARXeF3Jd0Zzx2rarv22raqHjjNOCVJ60//mHwl8LresXu7qtqy9Xi4Cthl0v1Ok3NUv517TfHgjBnlqtaVbwfWPlfdQFdsbQXcu8X45Un7unVVvXCacWojYIEljcf76e6TegGte2CzDXADcFOSPYAXjlh3lI8CRyTZM8mWwD9Nmr8N8IuqujXJw+numZrwM+A3wO9M0fb/APdL8pwk85McAuxJ109+RtrDMw5Msk2Su7UuFw8Ezq6qq4DTgDcl2bbNv0+Sia6MVwP3zBQP/ZAkjc07gKOS/G46W00c64Fv0t1b++IkmyR5Bl3PjVHOoSvIjm1tbJ7kkW3e6nLAR4A/SbI4yWZ0RdHZrbv9jCT5xyQPS7Jp687/l8B1wGV0ue9+Sf647c8mbdkH9OKcKp9qI2GBJY1BO+B/g+6M2Cm9WS+lK35upEtY0/ofUVX1WeA44Et0j5L90qRFXgS8OsmNwCvpCrKJdW8GXgd8vT1Z6RGT2v45XZ/zvwF+Dvwd8JSqunY6sU1yA91VuR/RJas3Ai/s9bF/Hl23kkvpugx+jO5mZdo+XQL8tHWxlCTNAlW1hO6E4Vvpjt3fA45o835F1w3+COAXwCHAyVO0s4Lu/t770uWJH7flYTU5oHVl/Ee6+6GuAu7Dmt/DW8B7gGvproz9AXBgVd1UVTfSPYDp2W3eT4E30HW9B3gX3YM/rkvyyTXcvua4rNwlVpIkSZK0pryCJUmSJEkDscCSJEmSpIFYYEmSJEnSQCywJEmSJGkgFliSJEmSNJBR/8hNY7TjjjvWokWLxh2GJI3V0qVLr62qncYdh0YzV0nS1LnKAmuWWbRoEUuWLBl3GJI0Vkl+OO4YNDVzlSRNnavsIihJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgbiPxqeZS5efj2Ljj513GGw7NgDxx2CJGmWmg25yjwlabbyCpYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoHVk+SeST6V5PIk30/y70k2TbI4yQG95Y5J8tJxxipJ2viYpyRp9rPAapIEOBn4ZFXtDtwP2Bp4HbAYOGDqtWe8rXlDtSVJ2jiYpyRpbrDAutPjgFur6j0AVbUCeAnwfOCNwCFJLkhySFt+zyRnJvlBkhdPNJLkuUnOacu+fSJJJbkpyZuSXAjst173TJK0ITBPSdIcYIF1pwcCS/sTquoGYBnwWuCkqlpcVSe12XsAfwg8HPinJJskeQBwCPDIqloMrAAOa8tvBZxdVQ+uqq+t652RJG1wzFOSNAfMH3cAc9ipVXUbcFuSa4CdgccD+wDndj052AK4pi2/Avj4qIaSHAkcCTBv253WcdiSpI3EYHkKzFWSNF0WWHe6FDi4PyHJtsC9gF+PWP623vAKuvcywPuq6mUjlr+1dee4i6o6ATgBYLOFu9fMQ5ckbQTGlqfAXCVJ02UXwTudDmyZ5Hlwxw2+bwLeC1wNbDPNNg5OcvfWxvZJdls34UqSNjLmKUmaAyywmqoq4OnAHyW5HPgucCvwcuAMupuF+zcPj2rjUuAVwGlJLgK+ACxc58FLkjZ45ilJmhvsIthTVVcCTx0x6zbgYatY70G94ZOAk0Yss/UQMUqSNl7mKUma/byCJUmSJEkDscCSJEmSpIFYYEmSJEnSQCywJEmSJGkgFliSJEmSNBALLEmSJEkaiAWWJEmSJA3EAkuSJEmSBmKBJUmSJEkDmT/uALSyvXZZwJJjDxx3GJIkTclcJUlT8wqWJEmSJA3EAkuSJEmSBmKBJUmSJEkDscCSJEmSpIFYYEmSJEnSQCywJEmSJGkgFlizzMXLr2fR0aey6OhTxx2KJEkjTeQqSdJdWWBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjSQGRVYSSrJm3rjL01yzGrWeUyS3+uNH5XkeTOOdOr2L0hy4lDtTbGNdybZc11uQ5I0DHOVJGmcZnoF6zbgGUl2nME6jwHuSFpVdXxVvX+G2x0pyQOAecD+SbYaos0R25hXVc+vqkvXRfuSpMGZqyRJYzPTAuvXwAnASybPSPLUJGcnOT/JF5PsnGQRcBTwknb2bv8kx7SziXskOae3/qIkF7fhfZJ8OcnSJJ9PsnCKeA4FPgCcBhzUa+vMJG9OsiTJt5M8LMnJSS5P8trecs9Nck6L7e1J5rXpNyV5U5ILgf1ae/u2eU9Kcl6SC5Oc3qY9PMk3275/I8n92/Qj2nY/17b9xhm+35KkmTNXmaskaWzW5B6stwGHJVkwafrXgEdU1UOAE4G/q6plwPHAm6tqcVV9dWLhqvoOsGmSe7dJhwAnJdkE+A/g4KraB3g38LopYjmkbesjdAms71dVtW/b/qeAPwceBByRZId2RvEQ4JFVtRhYARzW1t0KOLuqHlxVX5toMMlOwDuAZ1bVg4E/arO+A+zf9v2VwOt7cSxu29kLOCTJrpN3IsmRLcEuWXHz9VPsqiRpBsxV5ipJGov5M12hqm5I8n7gxcAtvVn3pEs6C4FNgSum0dxH6Q7ox7afhwD3p0suX0gCXbeKqyav2M7SXVtVP0qyHHh3ku2r6hdtkVPaz4uBS6rqqrbeD4BdgUcB+wDntu1sAVzT1lkBfHxEvI8AvlJVV7T3YmJbC4D3JdkdKGCT3jqnV9X1bduXArsBV/YbraoT6M62stnC3WuqN0uSND3mKnOVJI3Lmj5F8Djgz+jOnk34D+CtVbUX8H+BzafRzknAs5LcD6iquhwIXZJZ3F57VdUTR6x7KLBHkmXA94FtgWf25t/Wfv6mNzwxPr9t53297dy/qo5py9xaVSumEf+E1wBnVNWDgKey8r73t72CNShqJUlr5DjMVX3mKklaD9aowGpnwz5Kl7gmLACWt+HDe9NvBLaZop3v0x3I/5EugQFcBuyUZD+AJJskeWB/vSR3A54F7FVVi6pqEV2/9sldL1bldODgJHdvbW6fZLfVrHMW8OiJriJJtm/T+/t+xAxikCStI+Yqc5UkjcPa/B+sNwH9JzQdA/x3kqXAtb3pnwaePnHj8Ih2TgKeS5cEqapfAQcDb2g37l5A78lOzf7A8qr6SW/aV4A9V3GT8Urak5ZeAZyW5CLgC8Aq162qnwFHAie32CYS7RuBf05yPp71k6TZxFxlrpKk9SpVdqOeTTZbuHstPPw4AJYde+B4g5GkMUmytD38QbPQRK4yT0namE2Vq9bmCpYkSZIkqccCS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EAssSZIkSRqIBZYkSZIkDWT+uAPQyvbaZQFLjj1w3GFIkjQlc5UkTc0rWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgfiY9lnm4uXXs+joU8cdxiCW+QhfSdogmaskaWpewZIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJANrgCK8lNk8aPSPLWNnxUkuetpzheneQJ62NbkqS5wzwlSRu2+eMOYH2qquPX47Zeub62JUnaMJinJGnu2+CuYK1KkmOSvLQNvzjJpUkuSnJib/4HknwzyeVJXtCmb53k9CTnJbk4yUFt+qIk307yjiSXJDktyRZt3nuTHNyGH5bkG0kuTHJOkm3G8w5IkmYz85QkzX0b4hWsLZJc0BvfHjhlxHJHA/euqtuSbNebvjfwCGAr4PwkpwLXAE+vqhuS7AiclWSizd2BQ6vqBUk+CjwT+OBEY0k2BU4CDqmqc5NsC9zSDyTJkcCRAPO23WkNd1uSNEfMuTzVljNXSdI0bIhXsG6pqsUTL2CqLhAXAR9K8lzg173pn6qqW6rqWuAM4OFAgNcnuQj4IrALsHNb/oqquqANLwUWTdrO/YGrqupcgKq6oar626OqTqiqfatq33lbLpj5HkuS5pI5l6fadHOVJE3DhlhgTdeBwNuAhwLnJpm4mleTlivgMGAnYJ+WDK8GNm/zb+stu4IN86qgJGn9M09J0hy0URZYSe4G7FpVZwB/DywAtm6zD0qyeZIdgMcA57b511TV7UkeC+w2g81dBixM8rC27W16SVKSpLswT0nS3LWxHkDnAR9MsoCuW8Vbquq6JNB1yTgD2BF4TVX9JMmHgE8nuRhYAnxnuhuqql8lOQT4j3Zj8S3AE4CbVr2mJGkjZp6SpDkqVZN7Gmy8khwD3FRV/zquGDZbuHstPPy4cW1+UMuOPXDcIUiao5Israp9xx3HbDMb8hSYqyQJps5VG2UXQUmSJElaFzbWLoIjVdUx445BkqSpmKckafbzCpYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EP8P1iyz1y4LWOJ/lZckzWLmKkmamlewJEmSJGkgFliSJEmSNBALLEmSJEkaiAWWJEmSJA3EAkuSJEmSBmKBJUmSJEkD8THts8zFy69n0dGnjjsMaaO2zMdPS6tkrpLGz1w1e3kFS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQOZUwVWkt9OcmKS7ydZmuR/ktxvTLG8M8me49i2JGn2MldJ0sZt/rgDmK4kAT4BvK+qnt2mPRjYGfju+o6nqp6/vrcpSZrdzFWSpLl0BeuxwO1VdfzEhKq6EDg/yelJzktycZKDAJIsSvKtiWWTvDTJMW34vkm+mOTCtt59kmw9RTtbJTm1LfutJIe06Wcm2bcN/1eSJUkuSfKq3jaXJXlVr8091sP7JEkaH3OVJG3k5swVLOBBwNIR028Fnl5VNyTZETgrySmraetDwLFV9Ykkm9MVmr+aop0nAT+pqgMBkiwY0d4/VNUvkswDTk+yd1Vd1OZdW1UPTfIi4KWAZxMlacNlrpKkjdxcuoI1lQCvT3IR8EVgF7quGKMXTrYBdqmqTwBU1a1VdfMq2rkY+IMkb0iyf1VdP6LZZyU5DzgfeCDQ7+9+cvu5FFg0RUxHtrOKS1bcPKp5SdIcZ66SpI3EXCqwLgH2GTH9MGAnYJ+qWgxcDWwO/JqV92/z1bQ/sp2q+i7wULrk9dokr+yvlOTedGf7Hl9VewOnTtrWbe3nCqa4YlhVJ1TVvlW177wtR510lCTNEeYqSdrIzaUC60vAZkmOnJiQZG9gN+Caqro9yWPbOHRJ5+5JdkiyGfAUgKq6Efhxkqe1NjZLsiWwYFQ7Se4B3FxVHwT+hS6B9W0L/BK4PsnOwJPXwb5LkuYGc5UkbeTmzD1YVVVJng4cl+Tv6fqzLwOOAd6S5GJgCfCdtvztSV4NnAMsn5je/DHw9jb/duCP6Pq6f3pyO8BewL8k+U1b9oWT4rowyflt+SuBrw+865KkOcJcJUlKVY07BvVstnD3Wnj4ceMOQ9qoLTv2wHGHsNFLsrSq9h13HBrNXCWNn7lq/KbKVXOpi6AkSZIkzWoWWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSDzxx2AVrbXLgtY4n/mliTNYuYqSZqaV7AkSZIkaSAWWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgfh/sGaZi5dfz6KjT71jfJn/Z0SSNMv0c5V5SpJW5hUsSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCa5IkT0tSSfZYzXL/k2S79RSWJEl3MFdJ0uxlgXVXhwJfaz+nVFUHVNV16yUiSZJWZq6SpFnKAqsnydbAo4A/A57dpi1M8pUkFyT5VpL92/RlSXZsw59MsjTJJUmO7LV3U5LXJbkwyVlJdh7DbkmSNiDmKkma3SywVnYQ8Lmq+i7w8yT7AM8BPl9Vi4EHAxeMWO9Pq2ofYF/gxUl2aNO3As6qqgcDXwFeMGqjSY5MsiTJkhU3Xz/oDkmSNjjmKkmaxSywVnYocGIbPrGNnwv8SZJjgL2q6sYR6704yYXAWcCuwO5t+q+Az7ThpcCiURutqhOqat+q2nfelguG2A9J0obLXCVJs9j8cQcwWyTZHngcsFeSAuYBBfwt8GjgQOC9Sf6tqt7fW+8xwBOA/arq5iRnApu32bdXVbXhFfh+S5LWgrlKkmY/r2Dd6WDgA1W1W1UtqqpdgSvoEtbVVfUO4J3AQyettwD435aw9gAesV6jliRtTMxVkjTLeZbqTocCb5g07ePAe4FfJrkduAl43qRlPgccleTbwGV0XS8kSVoXzFWSNMtZYDVV9dgR094CvGWK5Rf1Rp88xTJb94Y/Bnxs7aKUJG3MzFWSNPvZRVCSJEmSBmKBJUmSJEkDscCSJEmSpIFYYEmSJEnSQCywJEmSJGkgFliSJEmSNBALLEmSJEkaiAWWJEmSJA3EAkuSJEmSBjJ/3AFoZXvtsoAlxx447jAkSZqSuUqSpuYVLEmSJEkaiAWWJEmSJA3EAkuSJEmSBmKBJUmSJEkDscCSJEmSpIFYYEmSJEnSQHxM+yxz8fLrWXT0qeMOQ5LW2jIf473BMldJ2hCsqzzlFSxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNZFoFVpKnJakke7TxnZKcneT8JPuPWP6dSfYcOtgR27kgyYnreBvrZV8kSWvHXGWukqTZYLpXsA4FvtZ+AjweuLiqHlJVX+0vmGReVT2/qi4dMM67SPIAYB6wf5Kt1tE21su+SJIGYa6SJI3dagusJFsDjwL+DHh2ksXAG4GD2lm5LZLclORNSS4E9ktyZpJ92/pPSnJekguTnN6mPTzJN9tZxW8kuX+bfkSSk5N8LsnlSd64itAOBT4AnAYc1Iv3zCRvTrIkybeTPKy1eXmS1/aWe26Sc9o+vD3JvDZ9HPsiSVoL5ipzlSTNFvOnscxBwOeq6rtJfk53Ju6VwL5V9RcA7azc2VX1N22c9nMn4B3Ao6vqiiTbtza/A+xfVb9O8gTg9cAz27zFwEOA24DLkvxHVV05Iq5DgD8A9gD+H/Dh3rxfVdW+Sf4S+BSwD/AL4PtJ3gzcva3/yKq6Pcl/AocB7wfW+74kORI4EmDetjuN2FVJ0mqYq9bxvpirJGl6plNgHQr8exs+sY1/a9IyK4CPj1j3EcBXquoKgKr6RZu+AHhfkt2BAjbprXN6VV0PkORSYDdgpQN9O0t3bVX9KMly4N1Jtu+1f0r7eTFwSVVd1db7AbAr3VnOfYBzW1LaArhmHPvS2joBOAFgs4W714htS5JWzVy1DveltWWukqRpWGWB1c58PQ7YK0nRnREs4JJJi95aVStmsN3XAGdU1dOTLALO7M27rTe8Apif5OnAP7Vpz6dLnHskWdambUt3Ju4dk9r4zaT2fkO3zwHeV1UvGxHbOt2XGbQrSZoGc9Xw+zKDdiVJk6zuHqyDgQ9U1W5VtaiqdgWuoDuzNh1nAY9Ocm+4IwlCdyZteRs+YnWNVNUnqmpxVS0GzgOeBezVYlpE1zXk0FU0MdnpwMFJ7j4RV5Ld1se+SJIGZ64aeF8kSWtudQXWocAnJk37ODDqbNpdVNXP6Pprn9xuxD2pzXoj8M9JzmfmZ8r2B5ZX1U96074C7Jlk4TTjuhR4BXBakouALwCrXHcd7Yskae2Zq+5cx1wlSWOWKrtRzyabLdy9Fh5+3LjDkKS1tuzYA9d43SRLq2rfAcPRgMxVkjYEa5OnYOpcNd3/gyVJkiRJWg0LLEmSJEkaiAWWJEmSJA3EAkuSJEmSBmKBJUmSJEkDscCSJEmSpIFYYEmSJEnSQCywJEmSJGkgFliSJEmSNJD54w5AK9trlwUsWcv/Ki1J0rpkrpKkqXkFS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQNJVY07BvUkuRG4bNxxjLAjcO24gxhhNsY1G2OC2RnXbIwJjGsm1lVMu1XVTuugXQ3AXDUjszEmmJ1xzcaYwLhmYjbGBOs5V81fBxvS2rmsqvYddxCTJVliXNMzG2OC2RnXbIwJjGsmZmNMWi/MVdM0G2OC2RnXbIwJjGsmZmNMsP7jsougJEmSJA3EAkuSJEmSBmKBNfucMO4ApmBc0zcbY4LZGddsjAmMayZmY0xa92br5z4b45qNMcHsjGs2xgTGNROzMSZYz3H5kAtJkiRJGohXsCRJkiRpIBZYs0iSJyW5LMn3khy9nrf97iTXJPlWb9r2Sb6Q5PL287fa9CR5S4vzoiQPXUcx7ZrkjCSXJrkkyV/Okrg2T3JOkgtbXK9q0++d5Oy2/ZOSbNqmb9bGv9fmL1oXcbVtzUtyfpLPzKKYliW5OMkFSZa0aeP+DLdL8rEk30ny7ST7zYKY7t/eo4nXDUn+ahbE9ZL2e/6tJB9pv/9j/73SeMQ8NTkm89TMYzNPTT8uc9X043pJZlOuqipfs+AFzAO+D/wOsClwIbDnetz+o4GHAt/qTXsjcHQbPhp4Qxs+APgsEOARwNnrKKaFwEPb8DbAd4E9Z0FcAbZuw5sAZ7ftfRR4dpt+PPDCNvwi4Pg2/GzgpHX4Of418GHgM218NsS0DNhx0rRxf4bvA57fhjcFtht3TJPimwf8FNhtnHEBuwBXAFv0fp+OmA2/V77W/wvz1KiYzFMzj808Nf24zFXTi2PW5ap1+sb7mtEvx37A53vjLwNetp5jWMTKiesyYGEbXkj3f08A3g4cOmq5dRzfp4A/mE1xAVsC5wG/S/cP7OZP/jyBzwP7teH5bbmsg1juCZwOPA74TDuYjTWm1v4y7pq4xvYZAgvagTizJaYRMT4R+Pq446JLWlcC27ffk88Afzgbfq98rf8X5qnpxGeeWnUs5qnpx2Sumn4csy5X2UVw9pj45Zjw4zZtnHauqqva8E+Bndvweo+1Xb59CN1ZuLHH1bo4XABcA3yB7qzudVX16xHbviOuNv96YId1ENZxwN8Bv2njO8yCmAAKOC3J0iRHtmnj/AzvDfwMeE/rpvLOJFuNOabJng18pA2PLa6qWg78K/Aj4Cq635OlzI7fK61/5qlVME9Ny3GYp6bLXDVNszFXWWBpWqor82sc206yNfBx4K+q6obZEFdVraiqxXRn4x4O7LG+Y+hL8hTgmqpaOs44pvCoqnoo8GTgz5M8uj9zDJ/hfLpuRv9VVQ8BfknXnWGcMd2h9RH/P8B/T563vuNqfegPokv09wC2Ap60vrYvzYR5amXmqRmZbXkKzFUziWXW5SoLrNljObBrb/yebdo4XZ1kIUD7eU2bvt5iTbIJXdL6UFWdPFvimlBV1wFn0F163i7J/BHbviOuNn8B8POBQ3kk8H+SLANOpOt+8e9jjgm448wSVXUN8Am6RD/Oz/DHwI+r6uw2/jG6JDZbfq+eDJxXVVe38XHG9QTgiqr6WVXdDpxM97s29t8rjYV5agTz1LSZp2bGXDV9sy5XWWDNHucCu7cnnmxKd9n1lDHHdApweBs+nK5v+cT057UnwzwCuL53WXgwSQK8C/h2Vf3bLIprpyTbteEt6Prbf5sugR08RVwT8R4MfKmd3RlMVb2squ5ZVYvofne+VFWHjTMmgCRbJdlmYpiuv/a3GONnWFU/Ba5Mcv826fHApeOMaZJDubPLxcT2xxXXj4BHJNmy/T1OvFdj/b3S2JinJjFPTZ95ambMVTMy+3LVkDd0+Vrrm/QOoHsC0feBf1jP2/4IXb/V2+nOmvwZXX/U04HLgS8C27dlA7ytxXkxsO86iulRdJeYLwIuaK8DZkFcewPnt7i+BbyyTf8d4Bzge3SXzDdr0zdv499r839nHX+Wj+HOpzONNaa2/Qvb65KJ3+tZ8BkuBpa0z/CTwG+NO6a2ra3ozqIt6E0b93v1KuA77Xf9A8Bm4/698jW+F+apyTGZp9YsvsdgnppObIsxV003plmVq9I2JEmSJElaS3YRlCRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLc1aSSnLfNnx8kn+czrJrsJ3Dkpy2pnGurSRHJPnauLa/LiT5bJLDp5i3qH1e81e37KT19k9y2dCxStK6lOS9SV7bhtf4OLa6PLiu9fdjQ5HkpiS/M8W8lXLzqpadtN7Lk7xzyDg1+1hgaWySfC7Jq0dMPyjJTye+YE9HVR1VVa8ZIKaVvty3tj9UVU9c27bnopZAVrTEcUOSC5M8ZW3braonV9X7hly2qr5aVfdf29jWRJJL2nt0U3u/bu2Nv3wcMUkaTpJlSW5pf9NXt2Ji66G3M93j2KgTb0PlwbmofR6/ap/PL5J8Ickea9tuVW1dVT8Yctmqen1VPX9tY5upJPfq5aWb2nedX/bG91/fMW3ILLA0Tu8Dnpskk6b/MfChqvr1GGLaoM2kaO35ZlVtDWwH/CdwYpLthoxrrquqB7bkujXwVeAvJsar6vUTy63h+y9pdnhq+xt/KLAv8IrJC/g3Powk89ZgtTe2z2cXYDnwrmGjmtuq6ke9vDRxcuDBvWlfnVjW3+O1Z4GlcfoksANwx1mTJL8FPAV4f5KHJ/lmkuuSXJXkrUk2HdXQ5K4JSf62rfOTJH86adkDk5zfrshcmeSY3uyvtJ/XtTM6+43oBvB7Sc5Ncn37+Xu9eWcmeU2Srye5MclpSXacIuYvJ3lmG35kO5t0YBt/fJILJi3/r0n+N8kVSZ7cm74gybva/i5P8tqJ5NRi/3qSNyf5OXBMks1aWz9qZ2KPT7LFqBj7quo3wAeArYDdW/urbKtdjbygvdffT/Kk3vv0/DY8r7VxbZIfAAdO2u8zkzy/beu6JA/qzdupnVW+e5LHJPlxb97ft/fjxiSXJXl8m35Mkv9O8sE27+Ik90vysiTXtN+JQa5Y5s4ron+W5EfAlybH2ZZbluQJbfhuSY5u79fPk3w0yfZDxCNp7VXVcuCzwIPgji7of57kcuDyNu0p7dh3XZJvJNl7Yv0kD0lyXjv+nARs3ps3+Ti2a5KTk/ysHQ/emuQBwPHAfi1PXdeWnZwHX5Dke+mu6JyS5B69eZXkqCSXtxjfltzlZCdJNm/H2B3b+D8k+XWSbdv4a5Ic11vlt5Kc2vbt7CT36bW1R7orS79ox+Rn9ea9N8l/JfmfJL8EHpvkHkk+3vb9iiQvnubncwvwUWBxr/0p22o56OXtmHtjkqVJdu29TxO3IuzQ3scbkpwD3Ke/3Yllk/xuul4483rznp7kojZ8TJIP9t7fD7bP9rp03yl2bvPOTJfPv9E+50+3GD7UYjg3yaLpvCerk9HfFe6Isy0zufv+lN89ZIGlMeodBJ/Xm/ws4DtVdSGwAngJsCOwH/B44EWrazfdl/iXAn9AVwg8YdIiv2zb3I7uy/wLkzytzXt0+7ldO6PzzUltbw+cCryFrjj8N+DUJDv0FnsO8CfA3YFNWyyjfBl4TBv+feAHve3/fps/4XeBy+jeizcC7+olw/cCvwbuCzwEeCLw/Enr/gDYGXgdcCxwP7rkc1+6s32vnCLG/r7Pa/t1O/DDNnnKtpI8HHg/8Ld07/WjgWUjmn4BXVH9ELqzwgeP2n5V3QacDBzam/ws4MtVdc2kWO8P/AXwsKraBvjDSdt+Kl2x+FvA+cDn6Y6HuwCvBt7ea+s/W+Ib9bpoVKwj/D7wgBbH6vw/4GltnXsA/wu8bZrbkbSOtS/fB9AdOyY8je5Yu2eShwDvBv4vXZ54O3BKupNEm9KdXPwAsD3w38Azp9jOPOAzdMfbRXTHpxOr6tvAUbTeBVW13Yh1Hwf8M90xcmFr48RJiz0FeBiwd1vuLsenqroVOJfueET7+UPgkb3xfq56NvAqumPr9+hyDkm2Ar4AfJguNz4b+M8ke/bWfU5bfhvgG8CngQvbfj8e+Kskqz2Gtm0d2rZPkrutpq2/bssfAGwL/Clw84im3wbcSvd+/ml73UVVnU33PeNxk/btwyMWPxxYAOxK97tyFHBLb/6z6Xr17EJX0H0TeA/d7863gX/q7fdFq8hV/zkq1kkmf1dYnfey6u8eG7eq8uVrbC/gUcB1wOZt/OvAS6ZY9q+AT/TGC7hvG34v8No2/G7g2N5y9+svO6Ld44A3t+FFbdn5vflHAF9rw38MnDNp/W8CR7ThM4FX9Oa9CPjcFNt9PHBRG/4c3YHprDb+ZeAZve1/r7feli3G36Y7EN4GbNGbfyhwRm/dH/Xmhe7Af5/etP2AK6aI8Qi6A+h1dIXVLcCzptMW3ZeKN0/R7pnA89vwl4CjevOe2P8MJi37BOD7vWW/DjyvDT8G+HEbvi9wTVt+k0nbPgb4Qm/8qcBNwLw2vk3b/nZr+Dvdj3fi9+l3evPviLM3bRnwhDb8beDxvXkL23s/f03i8eXL19q/2t/oTe1Y+EO67tJbtHkFPK637H8Br5m0/mV0xcijgZ8A6c37Bnfmr/5xbD/gZ6P+9unlpd609/baeRddl7mJeVu348iiXsyP6s3/KHD0FPv+GrqTivOBnwJ/SXdybXO6nLBDb/vv7K13AN0JU4BDgK9OavftwD/11n1/b97v0stdbdrLgPdMEeN76Yqf64DfAFcAe0+nrfbZHDRFu0WXT+a192+P3rzX9z8DVv5O8lrg3W14G7pcuVsbPwb4YBv+0/b57z1i22cC/9AbfxPw2d74U4EL1uJ3uh/vESPeozvibOOL2jrzWc13D1+FfSw1VlX1tSTXAk9Lci7wcOAZAEnuR3eFaF+6omI+sHQazd5j0nI/7M9M8rt0yeFBdFeYNqM7izgd95jcXhvfpTf+097wzXSJbZRvAvdr3QEWA/8HeFXrivFw7uyuuFKbVXVzu3i1Nd1ZrE2Aq+68oMXdgCt76/aHd6J7L5f2lg9d8pjKWVX1qHQ3dL+LrkvnR6fR1q7A/6yi3Qn3mBTj5Pe37wxgy/YZXk33vn1i8kJV9b0kf0WXIB6Y5PPAX1fVT9oiV/cWvwW4tqpW9Mahe3+vm0b803Hl6he5w27AJ5L8pjdtBV1CWz5QPJJm7mlV9cUp5vX/xncDDk/y/3rTNqU71hWwvNo30maqY96uwA9rze5Hvgdw3sRIVd3Uun7twp1X86ebq75Ml4sfClxMdyXqXcAj6E7+/by37FRt7gb8blp3xmY+3ZW8CZPfw3tMWn4e3T2uU/nXqnpFknvRnbS8P3DRNNraFfj+KtqFLt/NZ/q56sPAN5K8kO47zXlVNWr5D7TtT9zb/EG6our2Nn9yrpo8PuSDVmaap1b33WOjZhdBzQbvp+uy91zg81U1cQD5L+A7wO5VtS3wcrov8KtzFd0Ba8K9Js3/MHAKsGtVLaDryz7RbrFqP6E7sPTdizX44ltVN9MVgn8JfKuqfkV3Juuv6a7SXDuNZq6kO4u0Y1Vt117bVtUD+5vqDV9Ld1B+YG/5BXXnDa+rivcm4IXAH7cuMKtr60om9VGfwuo+r34MK+iKu0Pb6zNVdeMUy364qh5F93kV8IZpxHIX6e4ru2mK1yXTbKb/GfySrjCdaH8eXfKecCXw5N57ul1VbV7dfR+SZqf+3/iVwOsm/Q1vWVUfoTve7dLr4g1TH/OuBO6V0Q8cmFGuat3mdmDNTtJ8g65YeTpdl+xL6WI+gJW7B67KlW3d/nuydVW9sLfM5PfwiknLb1NVB6xuQ1X1I7q8+u/p7gleXVvTyVU/o+vNMd1cdSldAfZkpu4eSFXdXlWvqqo9gd+j67b5vFHLrk5Wfprt5Nfx02hi8u/USrmKrtfMhOl899ioWWBpNng/XVeuF9A9WXDCNsANwE3pHrf6whHrjvJR4IgkeybZkl4f5V67v6iqW9t9Qs/pzfsZXfeCqf6Xxf/QXXV6TpL5SQ4B9qTrJ78mvkx3r9BEkjpz0vgqVdVVwGnAm5Jsm+4BCfdJ8vtTLP8b4B3Am5PcHSDJLtPp197W/wXwTuCV02jrXcCfpHtgx93avFGPzf0o8OIk90z3kJOjVxPGh+m6mxzGFEkryf2TPC7JZnTdRm6h+1xnrLpHH289xWtNksl3gc3TPWxlE7onkW3Wm3888Loku7V92SnJQWsSu6SxeAdwVLqHHSTJVu3vfRu6ngu/pjvmbZLkGXQ9FkY5h64gO7a1sXmSiXufrgbumSke/AR8hO74u7gdB18PnF1Vy2a6M72TgX/OnbnpG3T3C023wPoMXe7847bfmyR5WLoHdoxyDnBjuocVbZHuQRQPSvKwacb8Bboi88hptPVO4DVJdm+f195Z+b7qiZN7J9M9/GHLdPeOHb6aMD5MV+g9mil6ySR5bJK92om2G+i6Ia5prnrgKnLVUWvQ5AXAo9M93n0BXbfKiW3N6LvHxsgCS2PXDvjfoHs63Sm9WS+lK35upEtYJ02zvc/S3Vf1JbqbXL80aZEXAa9OciPdAxk+2lv3ZrqbO7+e7sbQR0xq++d0Z5j+Bvg58HfAU6Z5tWmUL9MVfF+ZYnw6nkfX/eRSugcifIzuvp2p/D3d+3JWkhuAL9KdnZyu44AD0j0Va8q2quocuodivBm4nm7fJl/9g+6z/TzdDcjn0SWxKdWdNxDfg+5JXqNsRtcN9Fq6Lit3p5ccxqmqrqf7HXwn3dnkXwL9pwr+O93fwWntd/QsunsIJM0BVbWE7oThW+mOyd+ju8eF1lPhGW38F3Qni0Ye89qX+qfS3QP0I7rjxCFt9peAS4CfputmP3ndLwL/CHycrki7D90DE9bUl+m6hJ3TG592rmo9DZ7YYvgJ3XH5Dax8cqm//Aq6XLuY7n6qa+mOmQtmEPO/0OXo+atp69/ovgecRlfkvAsY9WTdv6DrkvdTunu+3rOa7X+E7r67L63iO8Jv0+XsG+juv/0yK3ebHJtWpJ5E181yKXc9kTzT7x4blazcDViSJEmStKa8giVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjSQUf+8TmO044471qJFi8YdhiSN1dKlS6+tqp1Wv6TGwVwlSVPnKgusWWbRokUsWbJk3GFI0lgl+eG4Y9DUzFWSNHWusougJEmSJA3EAkuSJEmSBmKBJUmSJEkDscCSJEmSpIFYYEmSJEnSQCywJEmSJGkgFliSJEmSNBALLEmSJEkaiP9oeJa5ePn1LDr61PW+3WXHHrjetylJmptWlavMJ5I2dl7BkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssHqS3DPJp5JcnuT7Sf49yaZJFic5oLfcMUleOs5YJUkbH/OUJM1+FlhNkgAnA5+sqt2B+wFbA68DFgMHTL32jLc1b6i2JEkbB/OUJM0NFlh3ehxwa1W9B6CqVgAvAZ4PvBE4JMkFSQ5py++Z5MwkP0jy4olGkjw3yTlt2bdPJKkkNyV5U5ILgf3W655JkjYE5ilJmgMssO70QGBpf0JV3QAsA14LnFRVi6vqpDZ7D+APgYcD/5RkkyQPAA4BHllVi4EVwGFt+a2As6vqwVX1tXW9M5KkDY55SpLmgPnjDmAOO7WqbgNuS3INsDPweGAf4NyuJwdbANe05VcAHx/VUJIjgSMB5m270zoOW5K0kRgsT4G5SpKmywLrTpcCB/cnJNkWuBfw6xHL39YbXkH3XgZ4X1W9bMTyt7buHHdRVScAJwBstnD3mnnokqSNwNjyFJirJGm67CJ4p9OBLZM8D+64wfdNwHuBq4FtptnGwUnu3trYPslu6yZcSdJGxjwlSXOABVZTVQU8HfijJJcD3wVuBV4OnEF3s3D/5uFRbVwKvAI4LclFwBeAhes8eEnSBs88JUlzg10Ee6rqSuCpI2bdBjxsFes9qDd8EnDSiGW2HiJGSdLGyzwlSbOfV7AkSZIkaSAWWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSDzxx2AVrbXLgtYcuyB4w5DkqQpmaskaWpewZIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoE1y1y8/HoWHX3quMOQJGlKFy+/ftwhSNKsZYElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgcyowEpSSd7UG39pkmNWs85jkvxeb/yoJM+bcaRTt39BkhOHam+KbbwzyZ7rchuSpGGYqyRJ4zTTK1i3Ac9IsuMM1nkMcEfSqqrjq+r9M9zuSEkeAMwD9k+y1RBtjtjGvKp6flVdui7alyQNzlwlSRqbmRZYvwZOAF4yeUaSpyY5O8n5Sb6YZOcki4CjgJe0s3f7JzmmnU3cI8k5vfUXJbm4De+T5MtJlib5fJKFU8RzKPAB4DTgoF5bZyZ5c5IlSb6d5GFJTk5yeZLX9pZ7bpJzWmxvTzKvTb8pyZuSXAjs19rbt817UpLzklyY5PQ27eFJvtn2/RtJ7t+mH9G2+7m27TfO8P2WJM2cucpcJUljsyb3YL0NOCzJgknTvwY8oqoeApwI/F1VLQOOB95cVYur6qsTC1fVd4BNk9y7TToEOCnJJsB/AAdX1T7Au4HXTRHLIW1bH6FLYH2/qqp92/Y/Bfw58CDgiCQ7tDOKhwCPrKrFwArgsLbuVsDZVfXgqvraRINJdgLeATyzqh4M/FGb9R1g/7bvrwRe34tjcdvOXsAhSXadvBNJjmwJdsmKm6+fYlclSTNgrjJXSdJYzJ/pClV1Q5L3Ay8GbunNuidd0lkIbApcMY3mPkp3QD+2/TwEuD9dcvlCEui6VVw1ecV2lu7aqvpRkuXAu5NsX1W/aIuc0n5eDFxSVVe19X4A7Ao8CtgHOLdtZwvgmrbOCuDjI+J9BPCVqrqivRcT21oAvC/J7kABm/TWOb2qrm/bvhTYDbiy32hVnUB3tpXNFu5eU71ZkqTpMVeZqyRpXNb0KYLHAX9Gd/Zswn8Ab62qvYD/C2w+jXZOAp6V5H5AVdXlQOiSzOL22quqnjhi3UOBPZIsA74PbAs8szf/tvbzN73hifH5bTvv623n/lV1TFvm1qpaMY34J7wGOKOqHgQ8lZX3vb/tFaxBUStJWiPHYa7qM1dJ0nqwRgVWOxv2UbrENWEBsLwNH96bfiOwzRTtfJ/uQP6PdAkM4DJgpyT7ASTZJMkD++sluRvwLGCvqlpUVYvo+rVP7nqxKqcDBye5e2tz+yS7rWads4BHT3QVSbJ9m97f9yNmEIMkaR0xV5mrJGkc1ub/YL0J6D+h6Rjgv5MsBa7tTf808PSJG4dHtHMS8Fy6JEhV/Qo4GHhDu3H3AnpPdmr2B5ZX1U96074C7LmKm4xX0p609ArgtCQXAV8AVrluVf0MOBI4ucU2kWjfCPxzkvPxrJ8kzSbmKnOVJK1XqbIb9Wyy2cLda+Hhx7Hs2APHHYokjU2Spe3hD5qFNlu4e9121eXjDkOSxmqqXLU2V7AkSZIkST0WWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWLPMXrssYNmxB447DEmSprTXLgvGHYIkzVoWWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgcwfdwBa2cXLr2fR0aeOO4w7+Mh4SdJkQ+Uqc4ykDZFXsCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjSQDa7ASnLTpPEjkry1DR+V5HnrKY5XJ3nC+tiWJGnuME9J0oZt/rgDWJ+q6vj1uK1Xrq9tSZI2DOYpSZr7NrgrWKuS5JgkL23DL05yaZKLkpzYm/+BJN9McnmSF7TpWyc5Pcl5SS5OclCbvijJt5O8I8klSU5LskWb994kB7fhhyX5RpILk5yTZJvxvAOSpNnMPCVJc9+GeAVriyQX9Ma3B04ZsdzRwL2r6rYk2/Wm7w08AtgKOD/JqcA1wNOr6oYkOwJnJZloc3fg0Kp6QZKPAs8EPjjRWJJNgZOAQ6rq3CTbArcMsaOSpDnJPCVJG7ANscC6paoWT4wkOQLYd8RyFwEfSvJJ4JO96Z+qqluAW5KcATwcOBV4fZJHA78BdgF2bstfUVUXtOGlwKJJ27k/cFVVnQtQVTdMDiTJkcCRAPO23Wl6eylJmqvmXJ5qcZqrJGkaNqougpMcCLwNeChwbpKJYrMmLVfAYcBOwD4tKV4NbN7m39ZbdgVrULRW1QlVtW9V7TtvywUzXV2StGGaNXkKzFWSNF0bZYGV5G7ArlV1BvD3wAJg6zb7oCSbJ9kBeAxwbpt/TVXdnuSxwG4z2NxlwMIkD2vb3qaXJCVJugvzlCTNXRvrAXQe8MEkC4AAb6mq65JA1yXjDGBH4DVV9ZMkHwI+neRiYAnwneluqKp+leQQ4D/ajcW3AE8Ablr1mpKkjZh5SpLmqFRN7mmw8UpyDHBTVf3ruGLYbOHutfDw48a1+btYduyB4w5B0kYoydKqGnVf0kZtNuQpGC5XmWMkzWVT5aqNsougJEmSJK0LG2sXwZGq6phxxyBJ0lTMU5I0+3kFS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EAssSZIkSRqI/wdrltlrlwUs8T/bS5JmMXOVJE3NK1iSJEmSNBALLEmSJEkaiAWWJEmSJA3EAkuSJEmSBmKBJUmSJEkDscCSJEmSpIH4mPZZ5uLl17Po6FPHHYbEMh/BLGkK5qrV8xgqbby8giVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBzKkCK8lvJzkxyfeTLE3yP0nuN6ZY3plkz3FsW5I0e5mrJGnjNn/cAUxXkgCfAN5XVc9u0x4M7Ax8d33HU1XPX9/blCTNbuYqSdJcuoL1WOD2qjp+YkJVXQicn+T0JOcluTjJQQBJFiX51sSySV6a5Jg2fN8kX0xyYVvvPkm2nqKdrZKc2pb9VpJD2vQzk+zbhv8ryZIklyR5VW+by5K8qtfmHuvhfZIkjY+5SpI2cnPmChbwIGDpiOm3Ak+vqhuS7AicleSU1bT1IeDYqvpEks3pCs1fTdHOk4CfVNWBAEkWjGjvH6rqF0nmAacn2buqLmrzrq2qhyZ5EfBSwLOJkrThMldJ0kZuLl3BmkqA1ye5CPgisAtdV4zRCyfbALtU1ScAqurWqrp5Fe1cDPxBkjck2b+qrh/R7LOSnAecDzwQ6Pd3P7n9XAosmiKmI9tZxSUrbh7VvCRpjjNXSdJGYi4VWJcA+4yYfhiwE7BPVS0GrgY2B37Nyvu3+WraH9lOVX0XeChd8nptklf2V0pyb7qzfY+vqr2BUydt67b2cwVTXDGsqhOqat+q2nfelqNOOkqS5ghzlSRt5OZSgfUlYLMkR05MSLI3sBtwTVXdnuSxbRy6pHP3JDsk2Qx4CkBV3Qj8OMnTWhubJdkSWDCqnST3AG6uqg8C/0KXwPq2BX4JXJ9kZ+DJ62DfJUlzg7lKkjZyc+YerKqqJE8Hjkvy93T92ZcBxwBvSXIxsAT4Tlv+9iSvBs4Blk9Mb/4YeHubfzvwR3R93T89uR1gL+BfkvymLfvCSXFdmOT8tvyVwNcH3nVJ0hxhrpIkparGHYN6Nlu4ey08/LhxhyGx7NgDxx2CNmJJllbVvuOOQ6OZq1bPY6i04ZsqV82lLoKSJEmSNKtZYEmSJEnSQCywJEmSJGkgFliSJEmSNBALLEmSJEkaiAWWJEmSJA3EAkuSJEmSBmKBJUmSJEkDscCSJEmSpIHMH3cAWtleuyxgif/9XZI0i5mrJGlqXsGSJEmSpIFYYEmSJEnSQCywJEmSJGkgFliSJEmSNBALLEmSJEkaiAWWJEmSJA3EAkuSJEmSBmKBNctcvPx6Fh19KouOPnXcoUiSNNJErpIk3ZUFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigTVJkqclqSR7rGa5/0my3XoKS5KkO5irJGn2ssC6q0OBr7WfU6qqA6rquvUSkSRJKzNXSdIsZYHVk2Rr4FHAnwHPbtMWJvlKkguSfCvJ/m36siQ7tuFPJlma5JIkR/bauynJ65JcmOSsJDuPYbckSRsQc5UkzW4WWCs7CPhcVX0X+HmSfYDnAJ+vqsXAg4ELRqz3p1W1D7Av8OIkO7TpWwFnVdWDga8ALxi10SRHJlmSZMmKm68fdIckSRscc5UkzWIWWCs7FDixDZ/Yxs8F/iTJMcBeVXXjiPVenORC4CxgV2D3Nv1XwGfa8FJg0aiNVtUJVbVvVe07b8sFQ+yHJGnDZa6SpFls/rgDmC2SbA88DtgrSQHzgAL+Fng0cCDw3iT/VlXv7633GOAJwH5VdXOSM4HN2+zbq6ra8Ap8vyVJa8FcJUmzn1ew7nQw8IGq2q2qFlXVrsAVdAnr6qp6B/BO4KGT1lsA/G9LWHsAj1ivUUuSNibmKkma5TxLdadDgTdMmvZx4L3AL5PcDtwEPG/SMp8DjkrybeAyuq4XkiStC+YqSZrlLLCaqnrsiGlvAd4yxfKLeqNPnmKZrXvDHwM+tnZRSpI2ZuYqSZr97CIoSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQOZP+4AtLK9dlnAkmMPHHcYkiRNyVwlSVPzCpYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSA+pn2WuXj59Sw6+tRxhyFJa22Zj/HeYJmrJG0I1lWe8gqWJEmSJA3EAkuSJEmSBmKBJUmSJEkDscCSJEmSpIFYYEmSJEnSQCywJEmSJGkgFliSJEmSNBALLEmSJEkaiAWWJEmSJA3EAkuSJEmSBjKtAivJ05JUkj3a+E5Jzk5yfpL9Ryz/ziR7Dh3siO1ckOTEdbyN9bIvkqS1Y64yV0nSbDDdK1iHAl9rPwEeD1xcVQ+pqq/2F0wyr6qeX1WXDhjnXSR5ADAP2D/JVutoG+tlXyRJgzBXSZLGbrUFVpKtgUcBfwY8O8li4I3AQe2s3BZJbkrypiQXAvslOTPJvm39JyU5L8mFSU5v0x6e5JvtrOI3kty/TT8iyclJPpfk8iRvXEVohwIfAE4DDurFe2aSNydZkuTbSR7W2rw8yWt7yz03yTltH96eZF6bPo59kSStBXOVuUqSZov501jmIOBzVfXdJD+nOxP3SmDfqvoLgHZW7uyq+ps2Tvu5E/AO4NFVdUWS7Vub3wH2r6pfJ3kC8HrgmW3eYuAhwG3AZUn+o6quHBHXIcAfAHsA/w/4cG/er6pq3yR/CXwK2Af4BfD9JG8G7t7Wf2RV3Z7kP4HDgPcD49gXSdLaMVet+32RJE3DdAqsQ4F/b8MntvFvTVpmBfDxEes+AvhKVV0BUFW/aNMXAO9LsjtQwCa9dU6vqusBklwK7AasdKBvZ+muraofJVkOvDvJ9r32T2k/LwYuqaqr2no/AHalO8u5D3BuS0pbANeMY1/avCOBIwHmbbvTiE1LklbDXLUO96XNM1dJ0jSsssBqZ74eB+yVpOjOCBZwyaRFb62qFTPY7muAM6rq6UkWAWf25t3WG14BzE/ydOCf2rTn0yXOPZIsa9O2pTsT945JbfxmUnu/odvnAO+rqpeNiG2d7suoBqrqBOAEgM0W7l4z2LYkbfTMVcPvy6gGzFWSND2ruwfrYOADVbVbVS2qql2BK+jOrE3HWcCjk9wb7kiC0J1JW96Gj1hdI1X1iapaXFWLgfOAZwF7tZgW0XUNOXQVTUx2OnBwkrtPxJVkt/WxL5KkwZmrBt4XSdKaW12BdSjwiUnTPg6MOpt2F1X1M7ruBCe3G3FParPeCPxzkvOZXjfFvv2B5VX1k960rwB7Jlk4zbguBV4BnJbkIuALwCrXXUf7Iklae+aqO9cxV0nSmKXKq/yzyWYLd6+Fhx837jAkaa0tO/bANV43ydKq2nfAcDQgc5WkDcHa5CmYOldN9/9gSZIkSZJWwwJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNZP64A9DK9tplAUvW8r9KS5K0LpmrJGlqXsGSJEmSpIFYYEmSJEnSQCywJEmSJGkgFliSJEmSNBALLEmSJEkaiAWWJEmSJA3EAkuSJEmSBmKBJUmSJEkDscCSJEmSpIFYYEmSJEnSQFJV445BPUluBC4bdxxraUfg2nEHsZbm+j7M9fhh7u/DXI8fxrsPu1XVTmPatlZjA8lV07Uh/C3PhPu74dqY9hXWz/6OzFXz1/FGNXOXVdW+4w5ibSRZ4j6M11yPH+b+Psz1+GHD2AetM3M+V03XxvZ34P5uuDamfYXx7q9dBCVJkiRpIBZYkiRJkjQQC6zZ54RxBzAA92H85nr8MPf3Ya7HDxvGPmjd2Jh+NzamfQX3d0O2Me0rjHF/fciFJEmSJA3EK1iSJEmSNBALrFkkyZOSXJbke0mOHnc805FkWZKLk1yQZEmbtn2SLyS5vP38rXHH2Zfk3UmuSfKt3rSRMafzlvaZXJTkoeOL/E5T7MMxSZa3z+KCJAf05r2s7cNlSf5wPFHfKcmuSc5IcmmSS5L8ZZs+Zz6HVezDnPgckmye5JwkF7b4X9Wm3zvJ2S3Ok5Js2qZv1sa/1+YvGmf8Go+5mKdmai7mtZnYEHLgdM31XDkTG0JenYlZn4OrytcseAHzgO8DvwNsClwI7DnuuKYR9zJgx0nT3ggc3YaPBt4w7jgnxfdo4KHAt1YXM3AA8FkgwCOAs8cd/yr24RjgpSOW3bP9Pm0G3Lv9ns0bc/wLgYe24W2A77Y458znsIp9mBOfQ3svt27DmwBnt/f2o8Cz2/TjgRe24RcBx7fhZwMnjfsz8LXef2fmZJ5ag/2cc3lthvs353PgWu7rnDhGr8G+zvm8OtD+zorP1ytYs8fDge9V1Q+q6lfAicBBY45pTR0EvK8Nvw942vhCuauq+grwi0mTp4r5IOD91TkL2C7JwvUS6CpMsQ9TOQg4sapuq6orgO/R/b6NTVVdVVXnteEbgW8DuzCHPodV7MNUZtXn0N7Lm9roJu1VwOOAj7Xpkz+Dic/mY8Djk2T9RKtZYkPKUzM1q/PaTGwIOXC65nqunIkNIa/OxGzPwRZYs8cuwJW98R+z6l+U2aKA05IsTXJkm7ZzVV3Vhn8K7Dye0GZkqpjn2ufyF+1S/7t7XVhm9T60rmYPobuCMic/h0n7AHPkc0gyL8kFwDXAF+jO6F1XVb9ui/RjvCP+Nv96YIf1GrDGbdb9Dq8jG0pem4k5eexdC3PiGL2mNoS8OhOzMQdbYGltPaqqHgo8GfjzJI/uz6zuuuycelTlXIy5+S/gPsBi4CrgTWONZhqSbA18HPirqrqhP2+ufA4j9mHOfA5VtaKqFgP3pDuTt8d4I5JmhQ0ur83Ehr5/zKFj9JrYEPLqTMzWHGyBNXssB3btjd+zTZvVqmp5+3kN8Am6L2lXT1xmbj+vGV+E0zZVzHPmc6mqq9sX5t8A7+DOS9+zch+SbEJ3UPxQVZ3cJs+pz2HUPsy1zwGgqq4DzgD2o+smMr/N6sd4R/xt/gLg5+s3Uo3ZrP0dHtIGlNdmYk4de9fGXDxGT9eGkFdnYjbnYAus2eNcYPd0T/DalO4m8lPGHNMqJdkqyTYTw8ATgW/RxX14W+xw4FPjiXBGpor5FOB57Wk7jwCu711qn1Um9Z1+Ot1nAd0+PDvdU+DuDewOnLO+4+tr9+68C/h2Vf1bb9ac+Rym2oe58jkk2SnJdm14C+AP6PqwnwEc3Bab/BlMfDYHA19qZ0O18ZhzeWqmNrC8NhNz5ti7tubKMXqmNoS8OhOzPgev7VMyfA36RJQD6J6C8n3gH8YdzzTi/R26J7JcCFwyETPdfRmnA5cDXwS2H3esk+L+CN1l49vp+uD+2VQx0z1d523tM7kY2Hfc8a9iHz7QYryI7kCysLf8P7R9uAx48iyI/1F03RQuAi5orwPm0uewin2YE58DsDdwfovzW8Ar2/TfoUs63wP+G9isTd+8jX+vzf+dcX8GvsbyezOn8tQa7N+czGsz3Mc5nwPXcl/nxDF6DfZ1zufVgfZ3Vny+aRuUJEmSJK0luwhKkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigaU5J0kluW8bPj7JP05n2TXYzmFJTlvTONdWkiOSfG1c218Xknw2yeFTzFvUPq/5q1t20nr7J7ls6FjXpSTvTfLaccchaXz6x4G1OY6tLg+uaxvi8SzJTUl+Z4p5K+XmVS07ab2XJ3nnkHGua0mWJXnCuOOYiyywtN4l+VySV4+YflCSn058wZ6Oqjqqql4zQEwrfblvbX+oqp64tm3PRS2BrGiJ44YkFyZ5ytq2W1VPrqr3DblsVX21qu6/trGtqSRnJrm1vVcTr/3GFY+k4bQvmLe0v+urWzGx9dDbme5xbNSJt6Hy4FzUPo9ftc/nF0m+kGSPtW23qrauqh8MuWxVvb6qnr+2sa2p9h3nl708dd24YtkYWGBpHN4HPDdJJk3/Y+BDVfXrMcS0QZtJ0drzzaraGtgO+E/gxCTbDRnXBuQvWpKdeH1z3AFJGsxT27HwocC+wCsmL7CGx1hNkmTeGqz2xvb57AIsB941bFQblAf38tR24w5mQ2aBpXH4JLADsP/EhCS/BTwFeH+Shyf5ZpLrklyV5K1JNh3V0OSuCUn+tq3zkyR/OmnZA5Oc367IXJnkmN7sr7Sf101cgRjRDeD3kpyb5Pr28/d6885M8pokX09yY5LTkuw4RcxfTvLMNvzIdlbpwDb++CQXTFr+X5P8b5Irkjy5N31Bkne1/V2e5LUTyanF/vUkb07yc+CYJJu1tn7UzsQen2SLUTH2VdVvgA8AWwG7t/ZX2Va7GnlBe6+/n+RJvffp+W14Xmvj2iQ/AA6ctN9nJnl+29Z1SR7Um7dTO6t89ySPSfLj3ry/b+/HjUkuS/L4Nv2YJP+d5INt3sVJ7pfkZUmuab8Tg12xbNv6aft9+UqSB06x3I5JPtP28RdJvprkbm3ePZJ8PMnP2uf/4qHikzQzVbUc+CzwILjjisCfJ7kcuLxNe0o79l2X5BtJ9p5YP8lDkpzXjj8nAZv35k0+ju2a5OT2t//zdHnwAcDxwH7pXYHIXfPgC5J8rx1PTklyj968SnJUkstbjG9L7nKykySbt2Psjm38H5L8Osm2bfw1SY7rrfJbSU5t+3Z2kvv02toj3ZWlX7Rj8rN6896b5L+S/E+SXwKPXdPjXlXdAnwUWNxrf8q2Wg56ectRNyZZmmTX3vs0cSvCDu19vCHJOcB9+tudWDbJ77Zj/rzevKcnuagNH5Pkg73394Pts70u3XeKndu8M9Pl82+0z/nTLYYPtRjOTbJoOu/J6iS5T5IvtTiubdvYboplH55kSYvh6iT/1pv3iBbvdel6vDxmiPjmMgssrXe9g+DzepOfBXynqi4EVgAvAXYE9gMeD7xode2m+xL/UuAP6AqByf2Gf9m2uR3dl/kXJnlam/fo9nO7UVcgkmwPnAq8ha44/Dfg1CQ79BZ7DvAnwN2BTVsso3wZeEwb/n3gB73t/36bP+F3gcvo3os3Au/qJcP3Ar8G7gs8BHgi8PxJ6/4A2Bl4HXAscD+65HNfurN9r5wixv6+z2v7dTvwwzZ5yraSPBx4P/C3dO/1o4FlI5p+AV1R/RC6s8IHj9p+Vd0GnAwc2pv8LODLVXXNpFjvD/wF8LCq2gb4w0nbfipdsfhbwPnA5+mOg7sArwbe3mvrP1uyGPW6aFSsk3yW7vfw7sB5wIemWO5vgB8DO9F9Vi8HKl2R9Wngwhbf44G/SvKH09i2pIG1L98H0B07JjyN7li7Z5KHAO8G/i9dnng7cEq6k0Sb0p1c/ACwPfDfwDOn2M484DN0x9tFdH//J1bVt4GjaL0LRl2BSPI44J/pjpELWxsnTlrsKcDDgL3bcnc5plTVrcC5dDmJ9vOHwCN74/1c9WzgVXTH1u/R5RySbAV8Afgw3bHw2cB/Jtmzt+5z2vLbAN9gDY97bVuHtu0zjWPoX7flDwC2Bf4UuHlE028DbqV7P/+0ve6iqs6m+57xuEn79uERix8OLAB2pftdOQq4pTf/2XS9enahK+i+CbyH7nfn28A/9fb7olXkqv8cFWtP6H5f7gE8oMVzzBTL/jvw71W1bYvpo237u9B9P3pti++lwMeT7LSabW/YqsqXr/X+Ah4FXAds3sa/DrxkimX/CvhEb7yA+7bh9wKvbcPvBo7tLXe//rIj2j0OeHMbXtSWnd+bfwTwtTb8x8A5k9b/JnBEGz4TeEVv3ouAz02x3ccDF7Xhz9EVRWe18S8Dz+ht/3u99bZsMf423Rfx24AtevMPBc7orfuj3rzQHfjv05u2H3DFFDEeQVe8XUdXWN0CPGs6bdF9qXjzFO2eCTy/DX8JOKo374n9z2DSsk8Avt9b9uvA89rwY4Aft+H7Ate05TeZtO1jgC/0xp8K3ATMa+PbtO1vN8Pf5TPpkvJ17XXeiGW2a20vGPF7+2rgU0z6PaX70vajSdNeBrxnXf99+vLlq3vRnaC5qf1t/5Cuu/QWbV4Bj+st+1/AayatfxldMfJo4CdAevO+0TsO9I9j+wE/o5ePeuscQctLvWn948m76LrMTczbuh3DF/ViflRv/keBo6fY99fQnVScD/wU+Eu6k2ub0+WEHXrbf2dvvQPoTpgCHAJ8dVK7bwf+qbfu+3vzZnTca+vf2j6f3wBXAHtPp6322Rw0RbtFl0/mtfdvj9681/c/A1b+TvJa4N1teBu6XLlbGz8G+GAb/tP2+e89YttnAv/QG38T8Nne+FOBC9bgd7mAG7gzV71lxDJPA86f9Pv/hDb8FboiesdJ6/w98IFJ0z4PHL6u/z5n88srWBqLqvoacC3wtNaV4OG0szzpum19pl1qv4HuYDayu90k9wCu7I3/sD+zXb4/o3UVuJ7ujNF02p1o+4eTpv2Q7uzShJ/2hm+mS2yjfBO4X+sOsJjuas+u6bpiPJw7uyuu1GZVTZxZ2xrYDdgEuGriTBVd0rp7b93+e7ETXYG2tLf859r0qZxV3RnS3wJO4c4unatra1fg+6tod8IqP69JzgC2bJ/hIrr37ROTF6qq79EV5McA1yQ5Mb3uMcDVveFbgGurakVvHKb+3FblxVW1XXs9tHU9ObZ1PbmBO6+ijfp9+xe6M66nJflBkqPb9N2Ae/TPRtJd3dp5DeKTtOae1v62d6uqF1XXC2NC/xi2G/A3k/5md6U71t0DWF7t22cz1TFvV+CHtWb3I6+Uq6rqJuDnrFmumuht8VDgYrorUb8PPILu5N/Pp9HmbsDvTnpPDqM7UThh8ns40+Pev7ZctYjuOD7xsJDVtTWdXLUTXYE53Vz1YeAZSTYDnkF3wm3U8h+gK0JOTHdLwxuTbNKbPzlXTR5f0wetPLSXq16cZOeWJ5e3XPVBpv5e9Gd0J66/07opTjz4ajfgjya9z4+iu+K30bLA0ji9n67L3nOBz1fVxAHkv4DvALtXdyn65XRXTVbnKroD5oR7TZr/YbpCYdeqWkDXl32i3WLVfkJ3EOm7F90NtTPSCqWldGcDv1VVv6I7k/XXdFdprp1GM1fSXcHasXew3Laq+vf59PfpWrqD8gN7yy+o7sbg1cV7E/BC4I9bF5jVtXUlk/qoT2F1n1c/hhV0Z1oPba/PVNWNUyz74ap6FN3nVcAbphHLXaS7r+ymKV6XrGb15wAH0V1JW0CX+GHE73FV3VhVf1NVvwP8H+Cv0903diXdVcHteq9tquqANdkfSetE/zh7JfC6SX+zW1bVR+iOd7v0unjD1Me8K4F7ZfSDM2aUq1q3uR1Yg1xFl5fuDzydrkv2pXQxH8DK3QNX5cq2bv892bqqXthbZvJ7uEbHvar6EV1e/fd09wSvrq3p5Kqf0fXmmG6uupSuAHsyU3cPpKpur6pXVdWewO/Rddt83qhlVyfJJavIVcevZvXX073/e7XvW89liu9bVXV5VR1KdyL3DcDH2u/XlXRXsPrv81ZVdeya7M+GwgJL4/R+ui+gL6B7suCEbeguY9+U7nGrLxyx7igfBY5IsmeSLen1Ue61+4uqurXdJ/Sc3ryf0XUvmOp/WfwP3VWn5ySZn+QQYE+6fvJr4st09wpNJKkzJ42vUlVdBZwGvCnJtknulu5m1d+fYvnfAO8A3pzk7tD1m57u/TxV9QvgncArp9HWu4A/SffAjru1eaMem/tR4MVJ7pnuISdHj1im78N03U0OY4qkleT+SR7Xzh7eSlcI/mY6+zhZdY8+3nqK18gHVvRsQ1cA/5zuat/rp1ow3U3x921fvK6nuwfxN8A5wI3pHtqxRbsq9qAkD1uT/ZG0zr0DOKpdaU+SrdI9XGkbup4Lv6Y75m2S5Bl0PRZGOYeuIDu2tbF5kol7n64G7pkpHvwEfITu+Lu4HQdfD5xdVctmujO9k4F/zp256Rt0vT+mW2B9hi53/nHb702SPCzdAztGWavjXlV9ga7IPHIabb0TeE2S3dvntXdWvq964uTeyXQPitoy3b1jh68mjA/TFXqPprvX7i6SPDbJXunut7uBrhvimuaqB64iVx21mtW3oesCe326e6n+dqoFkzw3yU7tO8B1bfJv6K56PTXJH7b3ePN0D22555rsz4bCAktj0w7436B7Ot0pvVkvpSt+bqRLWCdNs73P0t1X9SW6LldfmrTIi4BXJ7mR7oEMH+2tezPdTbZfb5e4HzGp7Z/TnWH6G7ovzX8HPGWaV5tG+TLdge0rU4xPx/PoHqZxKfC/wMdY9SX5v6d7X85qXQG+yJ1dKabjOOCAdE/FmrKtqjqH7qEYb6YrGL7MXa/+QffZfp7uBuTz6JLYlOrOG4jvQfcAiVE2o7tH4Fq6Lit3p+tzv769n+4s5nK6z+esVSy7O937dxPdl7D/rKozWmJ/Cl13yCvo9umddFfEJM0yVbWE7oThW+mOyd+ju2eK1lPhGW38F3Qni0Ye89rf/lPp7gH6Ed1DcA5ps78EXAL8NMld8k9VfRH4R+DjdEXafegemLCmvkzXHf2c3vi0c1XrafDEFsNP6I7Lb6A7Vo9afojj3r/Q5ej5q2nr3+i+B5xGV+S8Cxj1ZN2/oOuS91O6e77es5rtf4SuK+WXVvEd4bfpcvYNdA+t+DJdt8H17VV0XUCvp3tQxary8JOAS5LcRPfAi2dX1S1VdSVdj42X052svpKuUNuoa4ys3B1YkiRJkrSmNurqUpIkSZKGZIElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSCj/omdxmjHHXesRYsWjTsMSRqrpUuXXltVO407Do1mrpKkqXOVBdYss2jRIpYsWTLuMCRprJL8cNwxaGrmKkmaOlfZRVCSJEmSBmKBJUmSJEkDscCSJEmSpIFYYEmSJEnSQCywJEmSJGkgFliSJEmSNBALLEmSJEkaiAWWJEmSJA3EfzQ8y1y8/HoWHX3quMO4w7JjDxx3CJKkWWa25arpMqdJWh+8giVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssHqS3DPJp5JcnuT7Sf49yaZJFic5oLfcMUleOs5YJUkbH/OUJM1+FlhNkgAnA5+sqt2B+wFbA68DFgMHTL32jLc1b6i2JEkbB/OUJM0NFlh3ehxwa1W9B6CqVgAvAZ4PvBE4JMkFSQ5py++Z5MwkP0jy4olGkjw3yTlt2bdPJKkkNyV5U5ILgf3W655JkjYE5ilJmgMssO70QGBpf0JV3QAsA14LnFRVi6vqpDZ7D+APgYcD/5RkkyQPAA4BHllVi4EVwGFt+a2As6vqwVX1tf52khyZZEmSJStuvn7d7J0kaa4bW54Cc5UkTdf8cQcwh51aVbcBtyW5BtgZeDywD3Bu15ODLYBr2vIrgI+PaqiqTgBOANhs4e61juOWJG0cBstTYK6SpOmywLrTpcDB/QlJtgXuBfx6xPK39YZX0L2XAd5XVS8bsfytrTuHJElrwjwlSXOAXQTvdDqwZZLnwR03+L4JeC9wNbDNNNs4OMndWxvbJ9lt3YQrSdrImKckaQ6wwGqqqoCnA3+U5HLgu8CtwMuBM+huFu7fPDyqjUuBVwCnJbkI+AKwcJ0HL0na4JmnJGlusItgT1VdCTx1xKzbgIetYr0H9YZPAk4asczWQ8QoSdp4mackafbzCpYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EAssSZIkSRqIBZYkSZIkDWT+uAPQyvbaZQFLjj1w3GFIkjQlc5UkTc0rWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgzTIXL7+eRUefyqKjTx13KJIkjWSukqSpWWBJkiRJ0kAssCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSBWGBJkiRJ0kAssCRJkiRpIDMqsJJUkjf1xl+a5JjVrPOYJL/XGz8qyfNmHOnU7V+Q5MSh2ptiG+9Msue63IYkaRjmKknSOM30CtZtwDOS7DiDdR4D3JG0qur4qnr/DLc7UpIHAPOA/ZNsNUSbI7Yxr6qeX1WXrov2JUmDM1dJksZmpgXWr4ETgJdMnpHkqUnOTnJ+ki8m2TnJIuAo4CXt7N3+SY5pZxP3SHJOb/1FSS5uw/sk+XKSpUk+n2ThFPEcCnwAOA04qNfWmUnenGRJkm8neViSk5NcnuS1veWem+ScFtvbk8xr029K8qYkFwL7tfb2bfOelOS8JBcmOb1Ne3iSb7Z9/0aS+7fpR7Ttfq5t+40zfL8lSTNnrjJXSdLYrMk9WG8DDkuyYNL0rwGPqKqHACcCf1dVy4DjgTdX1eKq+urEwlX1HWDTJPdukw4BTkqyCfAfwMFVtQ/wbuB1U8RySNvWR+gSWN+vqmrftv1PAX8OPAg4IskO7YziIcAjq2oxsAI4rK27FXB2VT24qr420WCSnYB3AM+sqgcDf9RmfQfYv+37K4HX9+JY3LazF3BIkl0n70SSI1uCXbLi5uun2FVJ0gyYq8xVkjQW82e6QlXdkOT9wIuBW3qz7kmXdBYCmwJXTKO5j9Id0I9tPw8B7k+XXL6QBLpuFVdNXrGdpbu2qn6UZDnw7iTbV9Uv2iKntJ8XA5dU1VVtvR8AuwKPAvYBzm3b2QK4pq2zAvj4iHgfAXylqq5o78XEthYA70uyO1DAJr11Tq+q69u2LwV2A67sN1pVJ9CdbWWzhbvXVG+WJGl6zFXmKkkalzV9iuBxwJ/RnT2b8B/AW6tqL+D/AptPo52TgGcluR9QVXU5ELoks7i99qqqJ45Y91BgjyTLgO8D2wLP7M2/rf38TW94Ynx+2877etu5f1Ud05a5tapWTCP+Ca8BzqiqBwFPZeV97297BWtQ1EqS1shxmKv6zFWStB6sUYHVzoZ9lC5xTVgALG/Dh/em3whsM0U736c7kP8jXQIDuAzYKcl+AEk2SfLA/npJ7gY8C9irqhZV1SK6fu2Tu16syunAwUnu3trcPsluq1nnLODRE11Fkmzfpvf3/YgZxCBJWkfMVeYqSRqHtfk/WG8C+k9oOgb47yRLgWt70z8NPH3ixuER7ZwEPJcuCVJVvwIOBt7Qbty9gN6TnZr9geVV9ZPetK8Ae67iJuOVtCctvQI4LclFwBeAVa5bVT8DjgRObrFNJNo3Av+c5Hw86ydJs4m5ylwlSetVquxGPZtstnD3Wnj4cQAsO/bA8QYjSWOSZGl7+INmIXOVJE2dq9bmCpYkSZIkqccCS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EAssSZIkSRqIBZYkSZIkDWT+uAPQyvbaZQFLjj1w3GFIkjQlc5UkTc0rWJIkSZI0EAssSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgfiY9lnm4uXXs+joU8cdxnqzzMf8StKcs7HlqqmYwySN4hUsSZIkSRqIBZYkSZIkDcQCS5IkSZIGYoElSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EAssSZIkSRqIBZYkSZIkDWSDK7CS3DRp/Igkb23DRyV53nqK49VJnrA+tiVJmjvMU5K0YZs/7gDWp6o6fj1u65Xra1uSpA2DeUqS5r4N7grWqiQ5JslL2/CLk1ya5KIkJ/bmfyDJN5NcnuQFbfrWSU5Pcl6Si5Mc1KYvSvLtJO9IckmS05Js0ea9N8nBbfhhSb6R5MIk5yTZZjzvgCRpNjNPSdLctyFewdoiyQW98e2BU0YsdzRw76q6Lcl2vel7A48AtgLOT3IqcA3w9Kq6IcmOwFlJJtrcHTi0ql6Q5KPAM4EPTjSWZFPgJOCQqjo3ybbALUPsqCRpTjJPSdIGbEMssG6pqsUTI0mOAPYdsdxFwIeSfBL4ZG/6p6rqFuCWJGcADwdOBV6f5NHAb4BdgJ3b8ldU1QVteCmwaNJ27g9cVVXnAlTVDZMDSXIkcCTAvG13mt5eSpLmqjmXp1qc5ipJmoaNqovgJAcCbwMeCpybZKLYrEnLFXAYsBOwT0uKVwObt/m39ZZdwRoUrVV1QlXtW1X7zttywUxXlyRtmGZNngJzlSRN10ZZYCW5G7BrVZ0B/D2wANi6zT4oyeZJdgAeA5zb5l9TVbcneSyw2ww2dxmwMMnD2ra36SVJSZLuwjwlSXPXxnoAnQd8MMkCIMBbquq6JNB1yTgD2BF4TVX9JMmHgE8nuRhYAnxnuhuqql8lOQT4j3Zj8S3AE4CbVr2mJGkjZp6SpDkqVZN7Gmy8khwD3FRV/zquGDZbuHstPPy4cW1+vVt27IHjDkHSLJRkaVWNui9pozYb8hRsfLlqKuYwaeM2Va7aKLsISpIkSdK6sLF2ERypqo4ZdwySJE3FPCVJs59XsCRJkiRpIBZYkiRJkjQQCyxJkiRJGogFliRJkiQNxAJLkiRJkgZigSVJkiRJA7HAkiRJkqSB+H+wZpm9dlnAEv8zvCRpFjNXSdLUvIIlSZIkSQOxwJIkSZKkgVhgSZIkSdJALLAkSZIkaSAWWJIkSZI0EAssSZIkSRqIj2mfZS5efj2Ljj513GFImsWW+XhsjZm5StJsNRtypFewJEmSJGkgFliSJEmSNBALLEmSJEkaiAWWJEmSJA3EAkuSJEmSBmKBJUmSJEkDscCSJEmSpIFYYEmSJEnSQCywJEmSJGkgFliSJEmSNBALLEmSJEkayJwqsJL8dpITk3w/ydIk/5PkfmOK5Z1J9hzHtiVJs5e5SpI2bvPHHcB0JQnwCeB9VfXsNu3BwM7Ad9d3PFX1/PW9TUnS7GaukiTNpStYjwVur6rjJyZU1YXA+UlOT3JekouTHASQZFGSb00sm+SlSY5pw/dN8sUkF7b17pNk6yna2SrJqW3ZbyU5pE0/M8m+bfi/kixJckmSV/W2uSzJq3pt7rEe3idJ0viYqyRpIzdnrmABDwKWjph+K/D0qrohyY7AWUlOWU1bHwKOrapPJNmcrtD81RTtPAn4SVUdCJBkwYj2/qGqfpFkHnB6kr2r6qI279qqemiSFwEvBe5yNjHJkcCRAPO23Wk1oUuSZjFzlSRt5ObSFaypBHh9kouALwK70HXFGL1wsg2wS1V9AqCqbq2qm1fRzsXAHyR5Q5L9q+r6Ec0+K8l5wPnAA4F+f/eT28+lwKJRMVXVCVW1b1XtO2/LUTlRkjTHmaskaSMxlwqsS4B9Rkw/DNgJ2KeqFgNXA5sDv2bl/dt8Ne2PbKeqvgs8lC55vTbJK/srJbk33dm+x1fV3sCpk7Z1W/u5grl1xVCSNHPmKknayM2lAutLwGatiwIASfYGdgOuqarbkzy2jUOXdO6eZIckmwFPAaiqG4EfJ3laa2OzJFsCC0a1k+QewM1V9UHgX+gSWN+2wC+B65PsDDx5Hey7JGluMFdJ0kZuzpylqqpK8nTguCR/T9effRlwDPCW/9/e/cfaXdd3HH++0iqozDIUTYMN1axZR9JZpXMQwSDTBWEZmrHNzk3ccM2WbbrEbIFscb83ZZkgy7YAzqBkG2ai0+HCj1UJcxs/ilBbQARHM9cxO1GYzAxLee+P82k5vdzSwv30nnO/5/lITs73+/n+OO/3ud/bd9/f7/eek2QbsAX4Ult/d5LfBW4Fdu4db34GuLQt3w38OKN73f9+7n6AdcAfJ3mirfuLc+LamuSOtv5XgX/unLokaYmwVkmSUlWTjkFjjli5plaee/Gkw5A0xXa876xJh3DYJbm9qjZMOg7Nz1olaVotZo08UK1aSrcISpIkSdJUs8GSJEmSpE5ssCRJkiSpExssSZIkSerEBkuSJEmSOrHBkiRJkqRObLAkSZIkqRMbLEmSJEnqxAZLkiRJkjpZPukAtL91x61gyyJ+A7UkSc+UtUqSDswrWJIkSZLUiQ2WJEmSJHVigyVJkiRJndhgSZIkSVInNliSJEmS1IkNliRJkiR14se0T5ltOx9h9fmf2Te/w4/BlSRNGWuVJB2YV7AkSZIkqRMbLEmSJEnqxAZLkiRJkjqxwZIkSZKkTmywJEmSJKkTGyxJkiRJ6sQGS5IkSZI6scGSJEmSpE5ssCRJkiSpExssSZIkSerEBmuOJG9OUknWHmS9f0hy9CKFJUnSPtYqSZpeNlhPtRH4fHs+oKo6s6oeXpSIJEnan7VKkqaUDdaYJEcBpwDnAW9tYyuT3JTkziTbk5zaxnckeXGb/rsktye5K8mmsf09muQPkmxNcnOSl04gLUnSgFirJGm62WDt72zg2qr6MvBQkhOBnwKuq6r1wCuBO+fZ7ueq6kRgA/CuJC9q4y8Abq6qVwI3AT8/34sm2ZRkS5Ite779SNeEJEmDY62SpClmg7W/jcBVbfqqNn8b8LNJfhtYV1Xfmme7dyXZCtwMrALWtPHvANe06duB1fO9aFVdVlUbqmrDsuev6JGHJGm4rFWSNMWWTzqAaZHkGOB0YF2SApYBBfwa8DrgLOCKJB+oqo+ObXca8Abg5Kr6dpIbgSPb4t1VVW16D77fkqQFsFZJ0vTzCtaTzgGurKrjq2p1Va0CHmBUsL5WVZcDHwJePWe7FcA3W8FaC5y0qFFLkmaJtUqSppxnqZ60EXj/nLGrgSuA/02yG3gUePucda4FfiHJPcC9jG69kCTpcLBWSdKUs8Fqqur184xdAlxygPVXj82+6QDrHDU2/XHg4wuLUpI0y6xVkjT9vEVQkiRJkjqxwZIkSZKkTmywJEmSJKkTGyxJkiRJ6sQGS5IkSZI6scGSJEmSpE5ssCRJkiSpExssSZIkSerEBkuSJEmSOlk+6QC0v3XHrWDL+86adBiSJB2QtUqSDswrWJIkSZLUiQ2WJEmSJHVigyVJkiRJndhgSZIkSVInNliSJEmS1IkNliRJkiR14se0T5ltOx9h9fmfmXQYkrRgO/wY78GyVkkagsNVp7yCJUmSJEmd2GBJkiRJUic2WJIkSZLUiQ2WJEmSJHVigyVJkiRJndhgSZIkSVInNliSJEmS1IkNliRJkiR1YoMlSZIkSZ3YYEmSJElSJ4fUYCV5c5JKsrbNH5vkliR3JDl1nvU/lOSE3sHO8zp3JrnqML/GouQiSVoYa5W1SpKmwaFewdoIfL49A/wQsK2qXlVV/zS+YpJlVfXOqrq7Y5xPkeT7gGXAqUlecJheY1FykSR1Ya2SJE3cQRusJEcBpwDnAW9Nsh64EDi7nZV7XpJHk/xJkq3AyUluTLKhbX9Gki8k2Zpkcxt7TZJ/bWcV/yXJ97bxdyT5RJJrk9yX5MKnCW0jcCVwPXD2WLw3JrkoyZYk9yT5gbbP+5L8/th6P53k1pbDpUmWtfFJ5CJJWgBrlbVKkqbF8kNY52zg2qr6cpKHGJ2Jey+woap+GaCdlbulqt7T5mnPxwKXA6+rqgeSHNP2+SXg1Kp6PMkbgD8EfqwtWw+8CngMuDfJn1bVV+eJ6yeBNwJrgV8B/nps2XeqakOSdwOfAk4EvgF8JclFwEva9q+tqt1J/hx4G/BRYBK5SJIWxlp1+HORJB2CQ2mwNgIfbNNXtfntc9bZA1w9z7YnATdV1QMAVfWNNr4C+EiSNUABzxnbZnNVPQKQ5G7geGC/f+jbWbqvV9W/J9kJfDjJMWP7/3R73gbcVVUPtu3+DVjF6CznicBtrSg9D9g1iVzask3AJoBlLzx2npeWJB2Eteow5tKWWask6RA8bYPVznydDqxLUozOCBZw15xV/6+q9jyD1/094HNV9ZYkq4Ebx5Y9Nja9B1ie5C3Ab7WxdzIqnGuT7GhjL2R0Ju7yOft4Ys7+nmCUc4CPVNUF88R2WHOZbwdVdRlwGcARK9fUM3htSZp51qr+ucy3A2uVJB2ag/0N1jnAlVV1fFWtrqpVwAOMzqwdipuB1yV5OewrgjA6k7azTb/jYDupqk9W1fqqWg98AfgJYF2LaTWjW0M2Ps0u5toMnJPkJXvjSnL8YuQiSerOWtU5F0nSs3ewBmsj8Mk5Y1cD851Ne4qq+m9GtxN8ov0h7sfaoguBP0pyB4d2m+K4U4GdVfWfY2M3ASckWXmIcd0N/CZwfZIvAjcAT7vtYcpFkrRw1qont7FWSdKEpcqr/NPkiJVrauW5F086DElasB3vO+tZb5vk9qra0DEcdWStkjQEC6lTcOBadajfgyVJkiRJOggbLEmSJEnqxAZLkiRJkjqxwZIkSZKkTmywJEmSJKkTGyxJkiRJ6sQGS5IkSZI6scGSJEmSpE5ssCRJkiSpk+WTDkD7W3fcCrYs8FulJUk6nKxVknRgXsGSJEmSpE5ssCRJkiSpExssSZIkSerEBkuSJEmSOrHBkiRJkqRObLAkSZIkqRMbLEmSJEnqxAZLkiRJkjqxwZIkSZKkTmywJEmSJKmTVNWkY9CYJN8C7p10HBPwYuDrkw5ikZnz7JjFvBea8/FVdWyvYNTXwGvVkH9fzW1pMrfpNW+tWj6JSPS07q2qDZMOYrEl2TJreZvz7JjFvGcx5xkz2Fo15GPX3JYmc1t6vEVQkiRJkjqxwZIkSZKkTmywps9lkw5gQmYxb3OeHbOY9yzmPEuG/PM1t6XJ3JamQebmh1xIkiRJUidewZIkSZKkTmywpkiSM5Lcm+T+JOdPOp5eknw4ya4k28fGjklyQ5L72vN3t/EkuaS9B19M8urJRf7sJVmV5HNJ7k5yV5J3t/Gh531kkluTbG15/04bf3mSW1p+H0vy3DZ+RJu/vy1fPdEEFiDJsiR3JLmmzQ865yQ7kmxLcmeSLW1s0Me3hlGnhlqThlx3ZqG2DLWGzGqtsMGaEkmWAX8GvAk4AdiY5ITJRtXNFcAZc8bOBzZX1Rpgc5uHUf5r2mMT8BeLFGNvjwPvqaoTgJOAX2o/z6Hn/RhwelW9ElgPnJHkJOD9wEVV9T3AN4Hz2vrnAd9s4xe19ZaqdwP3jM3PQs6vr6r1Yx+xO/Tje6YNqE5dwTBr0pDrzizUliHXkNmrFVXlYwoewMnAdWPzFwAXTDqujvmtBraPzd8LrGzTKxl9pwrApcDG+dZbyg/gU8AbZylv4PnAF4AfZPQlgsvb+L5jHbgOOLlNL2/rZdKxP4tcX8aoSJwOXANkBnLeAbx4ztjMHN+z+BhSnZqFmjTUujPE2jLkGjKrtcIrWNPjOOCrY/P/0caG6qVV9WCb/i/gpW16cO9Du3z/KuAWZiDvdpvDncAu4AbgK8DDVfV4W2U8t315t+WPAC9a1ID7uBj4deCJNv8ihp9zAdcnuT3JpjY2+ON7xg355zioY3eIdWfgteVihltDZrJWLJ90AFJVVZJBfpxlkqOAq4Ffrar/SbJv2VDzrqo9wPokRwOfBNZONqLDK8mPALuq6vYkp004nMV0SlXtTPIS4IYkXxpfONTjW8O31I/dodadodaWGaghM1krvII1PXYCq8bmX9bGhuprSVYCtOddbXww70OS5zAqcn9VVZ9ow4PPe6+qehj4HKNbG45OsveEznhu+/Juy1cADy1upAv2WuBHk+wArmJ0i8cHGXbOVNXO9ryL0X92XsMMHd8zasg/x0Ecu7NQdwZYWwZdQ2a1VthgTY/bgDXtU2OeC7wV+PSEYzqcPg2c26bPZXSv+N7xt7dPkjkJeGTsMvKSkdEpw78E7qmqD4wtGnrex7aziyR5HqP7/+9hVAzPaavNzXvv+3EO8NlqN14vFVV1QVW9rKpWM/q9/WxVvY0B55zkBUm+a+808MPAdgZ+fGvQdWrJH7tDrjtDri1DriEzXSsm/UdgPp58AGcCX2Z0X/FvTDqejnn9DfAgsJvR/bTnMbpfeDNwH/CPwDFt3TD6lKqvANuADZOO/1nmfAqj+46/CNzZHmfOQN7fD9zR8t4OvLeNvwK4Fbgf+FvgiDZ+ZJu/vy1/xaRzWGD+pwHXDD3nltvW9rhr779XQz++fQyjTg21Jg257sxKbRlaDZnlWpGWkCRJkiRpgbxFUJIkSZI6scGSJEmSpE5ssCRJkiSpExssSZIkSerEBkuSJEmSOrHBkiRJkqRObLAkSZIkqRMbLEmSJEnq5P8BnJOwFrRgC1AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "i = 1\n",
    "for k, v in diff_dict.items():\n",
    "    ax = fig.add_subplot(3,2,i)\n",
    "    ax.barh(v.sort_values('race')['race'].unique(), v.sort_values('race')['race'].value_counts(sort=False))\n",
    "    ax.set_title(k)\n",
    "    i += 1\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=1.5)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ac5993a-81d5-4f0c-b30b-1f598a9443ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2%}'.format\n",
    "def compare_ethnic_spread(base_df, hyp_df):\n",
    "    base_ethnicity_spread = base_df['race'].value_counts(normalize=True)\n",
    "    hyp_ethnicity_spread = hyp_df['race'].value_counts(normalize=True)\n",
    "\n",
    "    \n",
    "    print(\n",
    "'''          ACTUAL\n",
    "{}\\n--------------------------\n",
    "         PREDICTED\n",
    "{}\\n--------------------------\n",
    "         DIFFERENCE'''.format(base_ethnicity_spread, hyp_ethnicity_spread))\n",
    "    \n",
    "    diff = dict()\n",
    "    for race in hyp_df['race'].unique():\n",
    "        diff[race] = hyp_ethnicity_spread[race] - base_ethnicity_spread[race]\n",
    "        \n",
    "    print(\"\\n\".join(\"{:>17}  {:>6.2%}\".format(k, v) for k, v in diff.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb42aa3d-6782-4a63-a7d7-de6e9ef7ee0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        UNFILTERED\n",
      "\n",
      "          ACTUAL\n",
      "African-American   49.34%\n",
      "Caucasian          36.23%\n",
      "Hispanic            8.15%\n",
      "Other               5.37%\n",
      "Asian               0.54%\n",
      "Native American     0.36%\n",
      "Name: race, dtype: float64\n",
      "--------------------------\n",
      "         PREDICTED\n",
      "African-American   49.34%\n",
      "Caucasian          36.23%\n",
      "Hispanic            8.15%\n",
      "Other               5.37%\n",
      "Asian               0.54%\n",
      "Native American     0.36%\n",
      "Name: race, dtype: float64\n",
      "--------------------------\n",
      "         DIFFERENCE\n",
      " African-American   0.00%\n",
      "        Caucasian   0.00%\n",
      "            Other   0.00%\n",
      "         Hispanic   0.00%\n",
      "            Asian   0.00%\n",
      "  Native American   0.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"        UNFILTERED\\n\")\n",
    "compare_ethnic_spread(diff_values[0], diff_values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bffef329-15df-432b-bfe5-f97e07b8be11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    RECIDIVISM == TRUE\n",
      "\n",
      "          ACTUAL\n",
      "African-American   56.83%\n",
      "Caucasian          30.04%\n",
      "Hispanic            6.65%\n",
      "Other               5.58%\n",
      "Asian               0.54%\n",
      "Native American     0.36%\n",
      "Name: race, dtype: float64\n",
      "--------------------------\n",
      "         PREDICTED\n",
      "African-American   75.22%\n",
      "Caucasian          17.78%\n",
      "Hispanic            4.37%\n",
      "Other               1.75%\n",
      "Asian               0.58%\n",
      "Native American     0.29%\n",
      "Name: race, dtype: float64\n",
      "--------------------------\n",
      "         DIFFERENCE\n",
      " African-American  18.38%\n",
      "        Caucasian  -12.25%\n",
      "         Hispanic  -2.28%\n",
      "            Other  -3.83%\n",
      "            Asian   0.04%\n",
      "  Native American  -0.07%\n"
     ]
    }
   ],
   "source": [
    "print(\"    RECIDIVISM == TRUE\\n\")\n",
    "compare_ethnic_spread(diff_values[2], diff_values[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d64080a9-5b47-48fb-8f42-af085acb25cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RECIDIVISM == FALSE\n",
      "\n",
      "          ACTUAL\n",
      "African-American   45.55%\n",
      "Caucasian          39.36%\n",
      "Hispanic            8.91%\n",
      "Other               5.27%\n",
      "Asian               0.55%\n",
      "Native American     0.36%\n",
      "Name: race, dtype: float64\n",
      "--------------------------\n",
      "         PREDICTED\n",
      "African-American   42.57%\n",
      "Caucasian          41.05%\n",
      "Hispanic            9.14%\n",
      "Other               6.32%\n",
      "Asian               0.53%\n",
      "Native American     0.38%\n",
      "Name: race, dtype: float64\n",
      "--------------------------\n",
      "         DIFFERENCE\n",
      " African-American  -2.97%\n",
      "        Caucasian   1.69%\n",
      "            Other   1.05%\n",
      "         Hispanic   0.23%\n",
      "            Asian  -0.01%\n",
      "  Native American   0.02%\n"
     ]
    }
   ],
   "source": [
    "print(\"   RECIDIVISM == FALSE\\n\")\n",
    "compare_ethnic_spread(diff_values[4], diff_values[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
