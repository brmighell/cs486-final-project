{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d6020ca-531b-4c7f-a533-c8507b5cadec",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92ebccfa-017f-4658-bd84-bd4242c3f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f37ae-2ab1-49ae-8f9e-48be02192c72",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6294c3-ebef-4ba8-85c8-db0b5115d222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>...</th>\n",
       "      <th>r_offense_date</th>\n",
       "      <th>r_charge_desc</th>\n",
       "      <th>r_jail_in</th>\n",
       "      <th>r_jail_out</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>num_vr_cases</th>\n",
       "      <th>vr_case_number</th>\n",
       "      <th>vr_charge_degree</th>\n",
       "      <th>vr_offense_date</th>\n",
       "      <th>vr_charge_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>1947-04-18 00:00:00.000000</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>michael ryan</td>\n",
       "      <td>michael</td>\n",
       "      <td>ryan</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1985-02-06 00:00:00.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1982-01-22 00:00:00.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-07-05 00:00:00.000000</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13009779CF10A</td>\n",
       "      <td>(F3)</td>\n",
       "      <td>2013-07-05 00:00:00.000000</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1991-05-14 00:00:00.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-06-16 00:00:00.000000</td>\n",
       "      <td>Driving Under The Influence</td>\n",
       "      <td>2013-06-16 09:05:47.000000</td>\n",
       "      <td>2013-06-16 07:18:55.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1993-01-21 00:00:00.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11752</th>\n",
       "      <td>11753</td>\n",
       "      <td>patrick hamilton</td>\n",
       "      <td>patrick</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>1968-05-02 00:00:00.000000</td>\n",
       "      <td>47</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11753</th>\n",
       "      <td>11754</td>\n",
       "      <td>raymond hernandez</td>\n",
       "      <td>raymond</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1993-06-24 00:00:00.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-11 00:00:00.000000</td>\n",
       "      <td>Driving License Suspended</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11754</th>\n",
       "      <td>11755</td>\n",
       "      <td>dieuseul pierre-gilles</td>\n",
       "      <td>dieuseul</td>\n",
       "      <td>pierre-gilles</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>1981-01-24 00:00:00.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11755</th>\n",
       "      <td>11756</td>\n",
       "      <td>scott lomagistro</td>\n",
       "      <td>scott</td>\n",
       "      <td>lomagistro</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1986-12-04 00:00:00.000000</td>\n",
       "      <td>29</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11756</th>\n",
       "      <td>11757</td>\n",
       "      <td>chin yan</td>\n",
       "      <td>chin</td>\n",
       "      <td>yan</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>1982-02-19 00:00:00.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11757 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                    name     first           last   sex  \\\n",
       "0          1        miguel hernandez    miguel      hernandez  Male   \n",
       "1          2            michael ryan   michael           ryan  Male   \n",
       "2          3             kevon dixon     kevon          dixon  Male   \n",
       "3          4                ed philo        ed          philo  Male   \n",
       "4          5             marcu brown     marcu          brown  Male   \n",
       "...      ...                     ...       ...            ...   ...   \n",
       "11752  11753        patrick hamilton   patrick       hamilton  Male   \n",
       "11753  11754       raymond hernandez   raymond      hernandez  Male   \n",
       "11754  11755  dieuseul pierre-gilles  dieuseul  pierre-gilles  Male   \n",
       "11755  11756        scott lomagistro     scott     lomagistro  Male   \n",
       "11756  11757                chin yan      chin            yan  Male   \n",
       "\n",
       "                   race                         dob  age          age_cat  \\\n",
       "0                 Other  1947-04-18 00:00:00.000000   69  Greater than 45   \n",
       "1             Caucasian  1985-02-06 00:00:00.000000   31          25 - 45   \n",
       "2      African-American  1982-01-22 00:00:00.000000   34          25 - 45   \n",
       "3      African-American  1991-05-14 00:00:00.000000   24     Less than 25   \n",
       "4      African-American  1993-01-21 00:00:00.000000   23     Less than 25   \n",
       "...                 ...                         ...  ...              ...   \n",
       "11752             Other  1968-05-02 00:00:00.000000   47  Greater than 45   \n",
       "11753         Caucasian  1993-06-24 00:00:00.000000   22     Less than 25   \n",
       "11754             Other  1981-01-24 00:00:00.000000   35          25 - 45   \n",
       "11755         Caucasian  1986-12-04 00:00:00.000000   29          25 - 45   \n",
       "11756             Asian  1982-02-19 00:00:00.000000   34          25 - 45   \n",
       "\n",
       "       juv_fel_count  ...              r_offense_date  \\\n",
       "0                  0  ...                         NaN   \n",
       "1                  0  ...                         NaN   \n",
       "2                  0  ...  2013-07-05 00:00:00.000000   \n",
       "3                  0  ...  2013-06-16 00:00:00.000000   \n",
       "4                  0  ...                         NaN   \n",
       "...              ...  ...                         ...   \n",
       "11752              0  ...                         NaN   \n",
       "11753              0  ...  2014-10-11 00:00:00.000000   \n",
       "11754              0  ...                         NaN   \n",
       "11755              0  ...                         NaN   \n",
       "11756              0  ...                         NaN   \n",
       "\n",
       "                     r_charge_desc                   r_jail_in  \\\n",
       "0                              NaN                         NaN   \n",
       "1                              NaN                         NaN   \n",
       "2      Felony Battery (Dom Strang)                         NaN   \n",
       "3      Driving Under The Influence  2013-06-16 09:05:47.000000   \n",
       "4                              NaN                         NaN   \n",
       "...                            ...                         ...   \n",
       "11752                          NaN                         NaN   \n",
       "11753    Driving License Suspended                         NaN   \n",
       "11754                          NaN                         NaN   \n",
       "11755                          NaN                         NaN   \n",
       "11756                          NaN                         NaN   \n",
       "\n",
       "                       r_jail_out  is_violent_recid  num_vr_cases  \\\n",
       "0                             NaN                 0           NaN   \n",
       "1                             NaN                 0           NaN   \n",
       "2                             NaN                 1           NaN   \n",
       "3      2013-06-16 07:18:55.000000                 0           NaN   \n",
       "4                             NaN                 0           NaN   \n",
       "...                           ...               ...           ...   \n",
       "11752                         NaN                 0           NaN   \n",
       "11753                         NaN                 0           NaN   \n",
       "11754                         NaN                 0           NaN   \n",
       "11755                         NaN                 0           NaN   \n",
       "11756                         NaN                 0           NaN   \n",
       "\n",
       "       vr_case_number  vr_charge_degree             vr_offense_date  \\\n",
       "0                 NaN               NaN                         NaN   \n",
       "1                 NaN               NaN                         NaN   \n",
       "2       13009779CF10A              (F3)  2013-07-05 00:00:00.000000   \n",
       "3                 NaN               NaN                         NaN   \n",
       "4                 NaN               NaN                         NaN   \n",
       "...               ...               ...                         ...   \n",
       "11752             NaN               NaN                         NaN   \n",
       "11753             NaN               NaN                         NaN   \n",
       "11754             NaN               NaN                         NaN   \n",
       "11755             NaN               NaN                         NaN   \n",
       "11756             NaN               NaN                         NaN   \n",
       "\n",
       "                    vr_charge_desc  \n",
       "0                              NaN  \n",
       "1                              NaN  \n",
       "2      Felony Battery (Dom Strang)  \n",
       "3                              NaN  \n",
       "4                              NaN  \n",
       "...                            ...  \n",
       "11752                          NaN  \n",
       "11753                          NaN  \n",
       "11754                          NaN  \n",
       "11755                          NaN  \n",
       "11756                          NaN  \n",
       "\n",
       "[11757 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('compas_people.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58d09ea-af50-446d-bd22-d00e6962356d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11757 entries, 0 to 11756\n",
      "Data columns (total 41 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       11757 non-null  int64  \n",
      " 1   name                     11757 non-null  object \n",
      " 2   first                    11757 non-null  object \n",
      " 3   last                     11757 non-null  object \n",
      " 4   sex                      11757 non-null  object \n",
      " 5   race                     11757 non-null  object \n",
      " 6   dob                      11757 non-null  object \n",
      " 7   age                      11757 non-null  int64  \n",
      " 8   age_cat                  11757 non-null  object \n",
      " 9   juv_fel_count            11757 non-null  int64  \n",
      " 10  juv_misd_count           11757 non-null  int64  \n",
      " 11  juv_other_count          11757 non-null  int64  \n",
      " 12  compas_screening_date    11757 non-null  object \n",
      " 13  decile_score             11757 non-null  int64  \n",
      " 14  score_text               0 non-null      float64\n",
      " 15  violent_recid            0 non-null      float64\n",
      " 16  priors_count             11757 non-null  int64  \n",
      " 17  days_b_screening_arrest  10577 non-null  float64\n",
      " 18  c_jail_in                10577 non-null  object \n",
      " 19  c_jail_out               10577 non-null  object \n",
      " 20  c_case_number            11015 non-null  object \n",
      " 21  c_days_from_compas       11015 non-null  float64\n",
      " 22  c_arrest_date            1858 non-null   object \n",
      " 23  c_offense_date           9157 non-null   object \n",
      " 24  c_charge_degree          11015 non-null  object \n",
      " 25  c_charge_desc            11008 non-null  object \n",
      " 26  is_recid                 11757 non-null  int64  \n",
      " 27  num_r_cases              3703 non-null   float64\n",
      " 28  r_case_number            3703 non-null   object \n",
      " 29  r_charge_degree          3703 non-null   object \n",
      " 30  r_days_from_arrest       2460 non-null   float64\n",
      " 31  r_offense_date           3703 non-null   object \n",
      " 32  r_charge_desc            3643 non-null   object \n",
      " 33  r_jail_in                2460 non-null   object \n",
      " 34  r_jail_out               2460 non-null   object \n",
      " 35  is_violent_recid         11757 non-null  int64  \n",
      " 36  num_vr_cases             0 non-null      float64\n",
      " 37  vr_case_number           882 non-null    object \n",
      " 38  vr_charge_degree         882 non-null    object \n",
      " 39  vr_offense_date          882 non-null    object \n",
      " 40  vr_charge_desc           882 non-null    object \n",
      "dtypes: float64(7), int64(9), object(25)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd9b89-4815-4b14-829c-3eecc140ff75",
   "metadata": {},
   "source": [
    "Okay, not too bad. We're gonna get rid of a lot of categories, though: mostly ones that assume that recidivism has already happened along with some that are unique, like `name` and `c_case_number`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f3a6580-5084-4211-ab6b-69edf42b0391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['name', 'first', 'last', \n",
    "              'score_text', 'violent_recid', 'c_case_number', \n",
    "              'c_offense_date', 'c_charge_desc', 'r_case_number', \n",
    "              'r_charge_degree', 'r_days_from_arrest', 'r_offense_date', \n",
    "              'r_charge_desc', 'r_jail_in', 'r_jail_out', \n",
    "              'is_violent_recid', 'num_vr_cases', 'vr_case_number', \n",
    "              'vr_charge_degree', 'vr_offense_date', 'vr_charge_desc',\n",
    "              'c_arrest_date', 'dob', 'days_b_screening_arrest',\n",
    "              'c_days_from_compas', 'id', 'compas_screening_date',\n",
    "              'num_r_cases'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c440bb3f-5184-4ada-a7aa-9edf31058d93",
   "metadata": {},
   "source": [
    "Next we're gonna consolidate `jail-in` and `jail-out` to `jail-time` so we only have to deal with a duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b85707-3e00-4695-83e8-75b279421a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['jail_time'] = (pd.to_datetime(df.c_jail_out) - pd.to_datetime(df.c_jail_in)).astype(\"timedelta64[s]\")\n",
    "df.jail_time.fillna(0, inplace=True)\n",
    "df.drop(['c_jail_in', 'c_jail_out'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942cedd2-4810-4869-812e-fe08d945dece",
   "metadata": {},
   "source": [
    "Okay, so, there's a couple different charge degrees missing values - we're gonna fill those in with the most common value for that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4720a08e-d953-4442-b7a6-1afc0289ee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(F3)     5913\n",
       "(M1)     2831\n",
       "(F2)      953\n",
       "(M2)      857\n",
       "(F1)      221\n",
       "(F7)      128\n",
       "(MO3)      83\n",
       "(F6)       10\n",
       "(NI0)       8\n",
       "(F5)        7\n",
       "(X)         1\n",
       "(CT)        1\n",
       "(TCX)       1\n",
       "(CO3)       1\n",
       "Name: c_charge_degree, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c_charge_degree.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82cabd40-52e1-4f4b-a8a3-88a1de94e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.c_charge_degree.fillna('(F3)', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f5f11c-2ad2-440e-8364-cf7fc95234c7",
   "metadata": {},
   "source": [
    "There's a number of entries that have a recidivism score of -1 - unfortunately, without a usable truth value, those entries aren't useful to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fb32008-bcc9-4c37-ae30-25deb449b073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.is_recid != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50290bd-e81f-4862-bcc9-25de7600a5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11038 entries, 0 to 11756\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   sex              11038 non-null  object \n",
      " 1   race             11038 non-null  object \n",
      " 2   age              11038 non-null  int64  \n",
      " 3   age_cat          11038 non-null  object \n",
      " 4   juv_fel_count    11038 non-null  int64  \n",
      " 5   juv_misd_count   11038 non-null  int64  \n",
      " 6   juv_other_count  11038 non-null  int64  \n",
      " 7   decile_score     11038 non-null  int64  \n",
      " 8   priors_count     11038 non-null  int64  \n",
      " 9   c_charge_degree  11038 non-null  object \n",
      " 10  is_recid         11038 non-null  int64  \n",
      " 11  jail_time        11038 non-null  float64\n",
      "dtypes: float64(1), int64(7), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195770f9-7fc5-46c0-bab0-d1765f4825c4",
   "metadata": {},
   "source": [
    "Much better. Now we're gonna split off the data that needs to be scaled and the data that needs to be encoded into a one-hot, do those transformations, then put them back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aee13d95-b909-4529-86bc-fc97e9ea9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "needs_scaling = df.drop(['sex', 'race', 'age_cat', 'c_charge_degree', 'is_recid'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(needs_scaling)\n",
    "\n",
    "needs_encoding = df[['sex', 'age_cat', 'c_charge_degree']]\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "one_hot_data = enc.fit_transform(needs_encoding)\n",
    "\n",
    "transformed_data = np.concatenate((scaled_data, one_hot_data), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78931c5-7b89-46cb-91af-da0b3edb58c5",
   "metadata": {},
   "source": [
    "This next bit is pretty straightforward: split the data into train/test/validation sets. The only slightly unusual thing we're going to do is to create new DataFrames to store the train/test/validation data so that we can come back and do some analysis at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "554313cd-9d67-4662-9cb5-a918907c5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['is_recid'].values\n",
    "x = transformed_data\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3)\n",
    "\n",
    "train_df = pd.DataFrame([])\n",
    "combo_df = pd.DataFrame([])\n",
    "test_df = pd.DataFrame([])\n",
    "valid_df = pd.DataFrame([])\n",
    "\n",
    "for train_index, combo_index in sss.split(x, y):\n",
    "    train_x, combo_x = x[train_index], x[combo_index]\n",
    "    train_y, combo_y = y[train_index], y[combo_index]\n",
    "    train_df = train_df.append(df.iloc[train_index])\n",
    "    combo_df = combo_df.append(df.iloc[combo_index])\n",
    "    \n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5)\n",
    "\n",
    "for test_index, valid_index in sss.split(combo_x, combo_y):\n",
    "    test_x, valid_x = combo_x[test_index], combo_x[valid_index]\n",
    "    test_y, valid_y = combo_y[test_index], combo_y[valid_index]\n",
    "    test_df = test_df.append(combo_df.iloc[test_index])\n",
    "    valid_df = valid_df.append(combo_df.iloc[valid_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c517cae4-065c-4d69-afc2-a6a2d330c914",
   "metadata": {},
   "source": [
    "Last but not least we define a couple helper methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33cf556c-ddc5-4a49-b2de-4bae37a5b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = {'acc': 0}\n",
    "\n",
    "# Tracks model with highest accuracy\n",
    "def update_best_model(acc, name, model, params):\n",
    "    if (acc > best_model['acc']):\n",
    "        best_model['acc'] = acc\n",
    "        best_model['name'] = name\n",
    "        best_model['model'] = model\n",
    "        best_model['params'] = params\n",
    "\n",
    "# Performs a grid search on a passed-in classifier\n",
    "def run_grid_search(folds, params, clf, name):\n",
    "    gscv = GridSearchCV(clf, params, cv=folds)\n",
    "    gscv.fit(train_x, train_y)\n",
    "    acc = accuracy_score(test_y, gscv.predict(test_x))\n",
    "    update_best_model(acc, name, gscv, gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a366b8a5-ce48-4173-aae9-55a4d7896351",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Algorithm Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a0cfcf-1909-484c-a571-d2920d05fb24",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we're gonna perform a grid search on several different algorithms: KNN, Decision Trees, Random Forest, Logistic Regression, and DNN. The accuracy score for each algorithm will be compared against each other and the model with the highest accuracy will be retained so we can test it against the validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e9233-a157-4051-ab21-8ecdeeab933c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95bb2ea5-a899-4f5c-b282-adee73bca232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = 10\n",
    "params = {'n_neighbors': list(range(3, 16))}\n",
    "\n",
    "run_grid_search(folds, params, KNeighborsClassifier(), 'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b3f43e-56f4-4956-807e-88a5512e445b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33131d1e-5dc7-4a04-9c87-1469740af6b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d85c222c-55ae-4547-8aef-4e13724ba342",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 10\n",
    "params = {'criterion': ('entropy', 'gini'),\n",
    "         'max_depth': [2, 3, 4, 5, 6, 7, 8]}\n",
    "\n",
    "run_grid_search(folds, params, DecisionTreeClassifier(), 'Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266f795-5146-4af2-9ca6-1dba388af3a3",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ca55806-6c4f-464a-82c2-7f191d34c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 10\n",
    "params = {'criterion': ('entropy', 'gini'),\n",
    "         'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
    "         'n_estimators': [10, 20, 30, 40]}\n",
    "\n",
    "run_grid_search(folds, params, RandomForestClassifier(), 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f389b7c2-6ab1-43b1-b38a-d67cfce5a9e2",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2f41001-ec07-420d-b2a1-d9c977d1bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 10\n",
    "params = {'penalty': ['l1', 'l2'],\n",
    "             'C': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "run_grid_search(folds, params, LogisticRegression(solver='liblinear'), 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0fad3c-1b7f-45e6-ba4d-2f8700b7fdc1",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb4fcdc-1d1d-47d3-bebf-5724f1a416be",
   "metadata": {},
   "source": [
    "WARNING: \n",
    "- Running the following code locally will write run logs to your machine \n",
    "- These files *do not* overwrite themselves. Run `!rm -rf ./logs` to delete old runs.\n",
    "- The `--logdir` argument for Tensorboard doesn't work great - this is a known issue. Instead of navigating to the provided directory, Tensorboard will (at least, on Windows) display all the logs in the first folder it finds (using a top-down search) that has logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a79cbaaf-0fb8-44a1-95d8-83232e80b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = tf.dtypes.cast(train_x, tf.float64)\n",
    "test_x = tf.dtypes.cast(test_x, tf.float64)\n",
    "valid_x = tf.dtypes.cast(valid_x, tf.float64)\n",
    "\n",
    "train_y = tf.dtypes.cast(train_y, tf.int64)\n",
    "test_y = tf.dtypes.cast(test_y, tf.int64)\n",
    "valid_y = tf.dtypes.cast(valid_y, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "488ccdee-6545-486b-b656-89bf4359f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c71277a-4742-4da1-92d3-175a8aa6a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([40, 80, 120]))\n",
    "HP_NUM_LAYERS = hp.HParam('num_layers', hp.Discrete([1, 2, 3]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', 'rmsprop']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_NUM_LAYERS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d4c4c2-04b9-440e-be5e-ec5e9f076833",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- Adding loss weights doesn't really affect accuracy but *can* massively decrease loss, for some reason. [0.2, 3] reduces loss from ~0.5 all the way down to 0.1-0.12 range\n",
    "- Deriving the loss weights from the dataset itself doesn't seem to make much of a difference\n",
    "- Messing around with the loss function doesn't really do much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8879d49-0cab-4029-a426-114e8dff2890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "\n",
    "  model = tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "  for i in range(hparams[HP_NUM_LAYERS]):\n",
    "        model.add(tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu))\n",
    "        \n",
    "  model.add(tf.keras.layers.Dropout(hparams[HP_DROPOUT]))\n",
    "  model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "#       loss_weights=[0.2,3],\n",
    "  )\n",
    "    \n",
    "  model.fit(train_x, train_y, epochs=20) \n",
    "  _, accuracy = model.evaluate(test_x, test_y)\n",
    "    \n",
    "  update_best_model(accuracy, 'DNN', model, hparams)\n",
    "\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bb924f7-c844-49ca-8f2e-a6acdf1135f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)\n",
    "    accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "425c8717-05fd-42e4-af7c-8ff6b79c8e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6124 - accuracy: 0.6608\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5800 - accuracy: 0.6951\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7026\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.7024\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5745 - accuracy: 0.6987\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7040\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7045\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7020\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7024\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7068: 0s - loss: 0.5725 - \n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7064\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7059\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7070\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.7059\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7070\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7024\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7062\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7108\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7064\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7103\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5755 - accuracy: 0.7077\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5995 - accuracy: 0.6811\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5799 - accuracy: 0.6948\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.6960\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7031\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7050\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7042\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.7028\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5689 - accuracy: 0.7061\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7050\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7085\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7066\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7088\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7058\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7079\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7099\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7137\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7116\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7107\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7107\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7130\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5716 - accuracy: 0.7041\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5922 - accuracy: 0.6857\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5760 - accuracy: 0.6996\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7066\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7054\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5688 - accuracy: 0.7070\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5690 - accuracy: 0.7075\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5670 - accuracy: 0.7096\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7118\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7092\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7106\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7149\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7150\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7163\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7160\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7163\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7180\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5551 - accuracy: 0.7150\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7174\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7228\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7216\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5771 - accuracy: 0.7107\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6066 - accuracy: 0.6759\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5828 - accuracy: 0.6926\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5771 - accuracy: 0.6974\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.6965\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.7020\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5757 - accuracy: 0.7020\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.6997\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7019: 0s - loss: 0.5719 - accu\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5718 - accuracy: 0.7013\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7046\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.7036\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7053\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7070\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7066\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7101\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7081\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.7050\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7089\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7066\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7089\n",
      "52/52 [==============================] - 0s 882us/step - loss: 0.5740 - accuracy: 0.7138\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5901 - accuracy: 0.6904\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.6991\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.7027\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5733 - accuracy: 0.7026\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7041\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7072\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7030\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5678 - accuracy: 0.7089\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7079\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7068\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7097\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7101\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.7119\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5644 - accuracy: 0.7123\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7130\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.7125\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7132\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7128\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5604 - accuracy: 0.7152\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5604 - accuracy: 0.7143\n",
      "52/52 [==============================] - 0s 921us/step - loss: 0.5771 - accuracy: 0.7035\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5968 - accuracy: 0.6842\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.6979\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.6997\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.7036\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7050\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.7068\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7053\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7079\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7099\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7090\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.7101\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7103\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7121\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7115\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7147\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7164\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5577 - accuracy: 0.7167\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7150\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.7209\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5573 - accuracy: 0.7149\n",
      "52/52 [==============================] - 0s 863us/step - loss: 0.5836 - accuracy: 0.6890\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6392 - accuracy: 0.6425\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5969 - accuracy: 0.6831\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5903 - accuracy: 0.6907\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5862 - accuracy: 0.6931\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5847 - accuracy: 0.6953\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5844 - accuracy: 0.6963\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5831 - accuracy: 0.6984\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5822 - accuracy: 0.6960\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5798 - accuracy: 0.6989\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.6998\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5789 - accuracy: 0.6976\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7005\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.7031\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5757 - accuracy: 0.7019\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.7044\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.7010\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5750 - accuracy: 0.7019\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.6987\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5745 - accuracy: 0.6996\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.7013\n",
      "52/52 [==============================] - 0s 784us/step - loss: 0.5811 - accuracy: 0.7047\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6196 - accuracy: 0.6694\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5966 - accuracy: 0.6817\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.6903\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.6921\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5824 - accuracy: 0.7000\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.6993\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5783 - accuracy: 0.7001\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5812 - accuracy: 0.6973\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5778 - accuracy: 0.7023\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5767 - accuracy: 0.7017: 0s - loss: 0.5871 - accura\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.7006\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5758 - accuracy: 0.7020\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.6975\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.7009\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7017: 0s - loss: 0.5774 - accuracy\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.7005\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5752 - accuracy: 0.7006\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.7031\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.7018\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7044\n",
      "52/52 [==============================] - 0s 863us/step - loss: 0.5798 - accuracy: 0.7017\n",
      "--- Starting trial: run-8\n",
      "{'num_units': 40, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6400 - accuracy: 0.6411\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.6866\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5907 - accuracy: 0.6941\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5840 - accuracy: 0.6948\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.6992\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5805 - accuracy: 0.6971\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.6995\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5782 - accuracy: 0.6975\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.7014\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5752 - accuracy: 0.7028\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7015\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.7020\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5722 - accuracy: 0.7031\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.7033\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5730 - accuracy: 0.7046\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7015\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7054\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7033\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.7063\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7054\n",
      "52/52 [==============================] - 0s 883us/step - loss: 0.5804 - accuracy: 0.6981\n",
      "--- Starting trial: run-9\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6141 - accuracy: 0.6701\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5928 - accuracy: 0.6888\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5863 - accuracy: 0.6962\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.6974\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.7009\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.6983\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5756 - accuracy: 0.7024\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5720 - accuracy: 0.6987\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5741 - accuracy: 0.7031\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7022\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5716 - accuracy: 0.7011\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.7052\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7049\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7040\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7057\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7057\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7042\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5690 - accuracy: 0.7068\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7094\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7064\n",
      "52/52 [==============================] - ETA: 5s - loss: 0.6092 - accuracy: 0.71 - 0s 784us/step - loss: 0.5741 - accuracy: 0.7035\n",
      "--- Starting trial: run-10\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6014 - accuracy: 0.6828\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.7000\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7045\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5743 - accuracy: 0.6996\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7085\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7059\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7041\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7075\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7077\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7084\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5643 - accuracy: 0.7094\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7101\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7132\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7120\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7110\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5624 - accuracy: 0.7133\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5627 - accuracy: 0.7132\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7147\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7141\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7115\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.7138\n",
      "--- Starting trial: run-11\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5945 - accuracy: 0.6895\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5805 - accuracy: 0.6986\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.7033\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.7028\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5712 - accuracy: 0.7026\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.7042: 0s - loss: 0.5568 - accu\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7077\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7074\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7061\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7094\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7097\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7089: 0s - loss: 0.5679 - accu\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7138\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7089\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.7159\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7094\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7146\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7168\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.7150\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5570 - accuracy: 0.7150\n",
      "52/52 [==============================] - 0s 804us/step - loss: 0.5844 - accuracy: 0.6957\n",
      "--- Starting trial: run-12\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5995 - accuracy: 0.6809\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5857 - accuracy: 0.6940\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5794 - accuracy: 0.7023\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5782 - accuracy: 0.6943\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7027\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.7027\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5751 - accuracy: 0.7062\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5712 - accuracy: 0.7026\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.7064\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5712 - accuracy: 0.7044\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.7013\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5687 - accuracy: 0.7030\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.7036\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.7093\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7062\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7061\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7050\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.7055\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.7058\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.7067\n",
      "52/52 [==============================] - 0s 863us/step - loss: 0.5779 - accuracy: 0.7041\n",
      "--- Starting trial: run-13\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5947 - accuracy: 0.6912\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5794 - accuracy: 0.6970\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5752 - accuracy: 0.7000\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5745 - accuracy: 0.7031\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.7015\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7026\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.71 - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7080\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7092\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.7057\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7067\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5687 - accuracy: 0.7072\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.7074\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7057\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7088\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7067\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.7084\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7085\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.7108\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5644 - accuracy: 0.7123\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7097\n",
      "52/52 [==============================] - 0s 745us/step - loss: 0.5755 - accuracy: 0.7065\n",
      "--- Starting trial: run-14\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5991 - accuracy: 0.6855\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5822 - accuracy: 0.6962\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7010\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.7019\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.7026\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7072\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7068\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7055\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.7084: 0s - loss: 0.5668 - accuracy: 0.\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7064\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.7092\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7137\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.7118\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5644 - accuracy: 0.7096\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7119\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5635 - accuracy: 0.7101\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7112\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.7150\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7146\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5601 - accuracy: 0.7155\n",
      "52/52 [==============================] - 0s 803us/step - loss: 0.5799 - accuracy: 0.7071\n",
      "--- Starting trial: run-15\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6266 - accuracy: 0.6595\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6038 - accuracy: 0.6808\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5957 - accuracy: 0.6853\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.6877\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5866 - accuracy: 0.6932\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5867 - accuracy: 0.6865\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5853 - accuracy: 0.6866\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.6916\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.6929\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5812 - accuracy: 0.6976\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.6948\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.6984\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.7004\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.6991\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.7028\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.6975\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5783 - accuracy: 0.6967\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.6995\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.6979\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5745 - accuracy: 0.7014\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5805 - accuracy: 0.7071\n",
      "--- Starting trial: run-16\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6252 - accuracy: 0.6644\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5979 - accuracy: 0.6824\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5940 - accuracy: 0.6843\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.6830\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.6897\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5863 - accuracy: 0.6905\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5849 - accuracy: 0.6957\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5822 - accuracy: 0.6967\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5822 - accuracy: 0.6948\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.6974\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.6967\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7013\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.6965\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5778 - accuracy: 0.7002\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.7026\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.6995\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.7005\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5764 - accuracy: 0.7026\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5752 - accuracy: 0.7026\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.7050\n",
      "52/52 [==============================] - 0s 784us/step - loss: 0.5816 - accuracy: 0.7041\n",
      "--- Starting trial: run-17\n",
      "{'num_units': 40, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6318 - accuracy: 0.6540\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.6802\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.6914\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.6938\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.6932\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.6941\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.6944\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7018\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5783 - accuracy: 0.7009\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.7005\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.6986\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5756 - accuracy: 0.6984\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.6995\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.6989\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7027\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7022\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7055\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.7055\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7004\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7041\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.7041\n",
      "--- Starting trial: run-18\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5987 - accuracy: 0.6816\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7010\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5752 - accuracy: 0.6991\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.7041\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7022\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.7022\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7050\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7032\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7031\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7068\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7052\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7063\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7075\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7105\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7096\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7080\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7075\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7079\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7054\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7084\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.7095\n",
      "--- Starting trial: run-19\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5866 - accuracy: 0.6870\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.6975\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7077\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7083\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5682 - accuracy: 0.7066\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7084\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5662 - accuracy: 0.7080\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5667 - accuracy: 0.7066\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7097\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7137\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7099\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5614 - accuracy: 0.7112\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5608 - accuracy: 0.7152\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7125\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7168\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7165\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5578 - accuracy: 0.7115\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5564 - accuracy: 0.7173\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5555 - accuracy: 0.7185\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5529 - accuracy: 0.7200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5821 - accuracy: 0.7005\n",
      "--- Starting trial: run-20\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5866 - accuracy: 0.6953\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.6987\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7032\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5695 - accuracy: 0.7045\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5696 - accuracy: 0.7058\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5684 - accuracy: 0.7045\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5659 - accuracy: 0.7099\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7108\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7062\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7124\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7115\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7103\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7151\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7132\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5556 - accuracy: 0.7180\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5545 - accuracy: 0.7212\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5518 - accuracy: 0.7189\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5515 - accuracy: 0.7207\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7238\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7248\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.6969\n",
      "--- Starting trial: run-21\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.6820\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5795 - accuracy: 0.6975\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.6976\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7022\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7068\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7052\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5712 - accuracy: 0.7042\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5696 - accuracy: 0.7039\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7032\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7072\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7037\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7045\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7081\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7059\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7089\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7097\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7064\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7059\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7097\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7108\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5751 - accuracy: 0.7095\n",
      "--- Starting trial: run-22\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.6913\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.7022\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7033\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7026\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7044\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7081\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7072\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7063\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7085\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7107\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7124\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7115\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7121\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7132\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7140\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7158\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7132\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7163\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7173\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7186\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.7011\n",
      "--- Starting trial: run-23\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5882 - accuracy: 0.6873\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.7010\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7068\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7033\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7068\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7057\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5669 - accuracy: 0.7057\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7093\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7092\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7140\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5628 - accuracy: 0.7146\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7134\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7145\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7181\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7149\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7186\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5523 - accuracy: 0.7226\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7215\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7226\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7251\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5889 - accuracy: 0.6950\n",
      "--- Starting trial: run-24\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6290 - accuracy: 0.6637\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.6881\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.6965\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.6984\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.6971\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.7010\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.6988\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5806 - accuracy: 0.6974\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7000\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5796 - accuracy: 0.7002\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6969\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.7045\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5758 - accuracy: 0.7041\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5769 - accuracy: 0.7013\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7072\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5757 - accuracy: 0.7041\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.7031\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7039\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7036\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.7049\n",
      "52/52 [==============================] - 0s 902us/step - loss: 0.5815 - accuracy: 0.6987\n",
      "--- Starting trial: run-25\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6176 - accuracy: 0.6595\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.6868\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.6929\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6971\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7031\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7001\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7049\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.6997\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7027\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.7036\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7024\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.7039\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7071\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.7041\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7067\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7054\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7036\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7070\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7045\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.7063\n",
      "52/52 [==============================] - 0s 862us/step - loss: 0.5765 - accuracy: 0.7132\n",
      "--- Starting trial: run-26\n",
      "{'num_units': 80, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6157 - accuracy: 0.6676\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.6896\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.6962\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.6958\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.6984\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.6995\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7031\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7050\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7014\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.6987\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7031\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5703 - accuracy: 0.7053\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7001\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7028\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7040\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7020\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7053\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7017\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.7045\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7046\n",
      "52/52 [==============================] - 0s 863us/step - loss: 0.5778 - accuracy: 0.7053\n",
      "--- Starting trial: run-27\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6103 - accuracy: 0.6743\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.6965\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.6971\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5745 - accuracy: 0.7030\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.7046\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7030\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.7001\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7005\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7068\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7050\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5687 - accuracy: 0.7042\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7028\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7030\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7053\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7076\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7071\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7096\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7084\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7140\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.7076\n",
      "52/52 [==============================] - 0s 765us/step - loss: 0.5766 - accuracy: 0.7095\n",
      "--- Starting trial: run-28\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5933 - accuracy: 0.6869\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.6995\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7008\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.7075\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7041\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7081\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7114\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7114\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7081\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7074\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7124\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7116\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.7125\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7118\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7128\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5586 - accuracy: 0.7171\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7168\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5571 - accuracy: 0.7163\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.7185\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5540 - accuracy: 0.7173\n",
      "52/52 [==============================] - 0s 824us/step - loss: 0.5737 - accuracy: 0.7101\n",
      "--- Starting trial: run-29\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5889 - accuracy: 0.6949\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7039\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7018\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7033\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7070\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7071\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7086\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7081\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7103\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7121\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7173\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7134\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7140\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7128\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7159\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7211\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7220\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7199\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7224\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7234\n",
      "52/52 [==============================] - 0s 843us/step - loss: 0.5814 - accuracy: 0.7101\n",
      "--- Starting trial: run-30\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5919 - accuracy: 0.6891\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.6935\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.7028\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.7032\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.7040\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7031\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7045\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7017\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7026\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5698 - accuracy: 0.7068\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7046\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.7063\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7085\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7048\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5687 - accuracy: 0.7057\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7079\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.7090\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.7068\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7088\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.7088\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7162\n",
      "--- Starting trial: run-31\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5920 - accuracy: 0.6914\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5784 - accuracy: 0.7015\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.7020\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7020\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5718 - accuracy: 0.7028\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7066\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7040\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7074\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7057\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7089\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7092\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7089\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7116\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7090\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7121\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5622 - accuracy: 0.7141\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.7162\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7129\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7158\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7133\n",
      "52/52 [==============================] - 0s 784us/step - loss: 0.5789 - accuracy: 0.7114\n",
      "--- Starting trial: run-32\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5865 - accuracy: 0.6901\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5789 - accuracy: 0.6984\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7031\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5720 - accuracy: 0.7066\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.7064\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7074\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.7081\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.7090\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7130\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5644 - accuracy: 0.7145\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7140\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7156\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7129\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7171\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7198\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5588 - accuracy: 0.7202\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5557 - accuracy: 0.7225\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7191\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5538 - accuracy: 0.7196\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7220\n",
      "52/52 [==============================] - 0s 843us/step - loss: 0.5858 - accuracy: 0.6975\n",
      "--- Starting trial: run-33\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6174 - accuracy: 0.6705\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5941 - accuracy: 0.6907\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5898 - accuracy: 0.6938\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5854 - accuracy: 0.6961\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5849 - accuracy: 0.6923\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.6967\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5820 - accuracy: 0.6954\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.6987\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5801 - accuracy: 0.6957\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.6987\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.7000\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.6971\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5786 - accuracy: 0.7013\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.7004\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.6987\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5773 - accuracy: 0.6991\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.7015\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.7024\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5746 - accuracy: 0.7064\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7037\n",
      "52/52 [==============================] - 0s 824us/step - loss: 0.5797 - accuracy: 0.7059\n",
      "--- Starting trial: run-34\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6188 - accuracy: 0.6648\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6913\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.6910\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.6969\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.6991\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7013\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7001\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.7049\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5750 - accuracy: 0.7033\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5743 - accuracy: 0.6992\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7040\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.7050\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.7046\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7035\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.7036\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7062\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5720 - accuracy: 0.7055\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.7046\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5719 - accuracy: 0.7072\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.7062\n",
      "52/52 [==============================] - 0s 785us/step - loss: 0.5756 - accuracy: 0.7083\n",
      "--- Starting trial: run-35\n",
      "{'num_units': 80, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6280 - accuracy: 0.6547\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5949 - accuracy: 0.6819\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.6890\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.6984\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.6963\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.7002\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.6996\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.7020\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.7000\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5769 - accuracy: 0.7017\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7036\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7036\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7031\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7022\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7059\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7040\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7050\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7036\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7054\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7031\n",
      "52/52 [==============================] - 0s 902us/step - loss: 0.5800 - accuracy: 0.7059\n",
      "--- Starting trial: run-36\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5985 - accuracy: 0.6778\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.6960\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.7015\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7055\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.6995\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7048\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7045\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7080\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7055\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7055\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7080\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7108\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7097\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7137\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5650 - accuracy: 0.7084\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.7079\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7127\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7103\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7115\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7099\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.7065\n",
      "--- Starting trial: run-37\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5861 - accuracy: 0.6976\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.6974\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7058\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7028\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7061\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7048\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.7074\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7089\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.7115\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7106\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7101\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7162\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7125\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7141\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5568 - accuracy: 0.7147\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5543 - accuracy: 0.7176\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.7158\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5518 - accuracy: 0.7195\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5514 - accuracy: 0.7184\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5495 - accuracy: 0.7213\n",
      "52/52 [==============================] - ETA: 4s - loss: 0.5942 - accuracy: 0.71 - 0s 726us/step - loss: 0.5788 - accuracy: 0.7023\n",
      "--- Starting trial: run-38\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'adam', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5870 - accuracy: 0.6901\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.6976\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7000\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.7020\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7011\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.7089\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7083\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7114\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7149\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7136\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5577 - accuracy: 0.7171\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7133\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7168\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7163\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7228\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7253\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5487 - accuracy: 0.7259\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5432 - accuracy: 0.7279\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7282\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7314\n",
      "52/52 [==============================] - 0s 902us/step - loss: 0.5932 - accuracy: 0.6969\n",
      "--- Starting trial: run-39\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5884 - accuracy: 0.6897\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.7031\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.7017\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5716 - accuracy: 0.7041\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.7005\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7075\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7058\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.7041\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7061\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7031\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7036\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7039\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7063\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7081\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.7089\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5651 - accuracy: 0.7081\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5647 - accuracy: 0.7086\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.7072\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7124\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7089\n",
      "52/52 [==============================] - 0s 686us/step - loss: 0.5777 - accuracy: 0.7041\n",
      "--- Starting trial: run-40\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5894 - accuracy: 0.6947\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5761 - accuracy: 0.7026\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.7054\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.7027\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7024\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.7040\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.7048\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7081\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.7103\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.7099\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5639 - accuracy: 0.7093\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7141\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5612 - accuracy: 0.7142\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7152\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5609 - accuracy: 0.7142\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5587 - accuracy: 0.7160\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7158\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7158\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7178\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7198\n",
      "52/52 [==============================] - 0s 927us/step - loss: 0.5796 - accuracy: 0.7083\n",
      "--- Starting trial: run-41\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'rmsprop', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5885 - accuracy: 0.6921\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7009\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.7031\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7044\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5691 - accuracy: 0.7061\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7106\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7112\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7118\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7159\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7160\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7162\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7169\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7181\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7178\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7202\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7233\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7238\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7243: 0s - loss: 0.5499 - accura\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7251\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7260\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.5844 - accuracy: 0.7059\n",
      "--- Starting trial: run-42\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6270 - accuracy: 0.6406\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.6872\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.6922\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.6935\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5786 - accuracy: 0.6956\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.6984\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5767 - accuracy: 0.7013\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5752 - accuracy: 0.7031\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7008\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.7004\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7026\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7046\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5731 - accuracy: 0.7037\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.6992\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7058\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.7041\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.7020\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.7057\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5721 - accuracy: 0.7026\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7061\n",
      "52/52 [==============================] - 0s 785us/step - loss: 0.5775 - accuracy: 0.7083\n",
      "--- Starting trial: run-43\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6080 - accuracy: 0.6771\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.6971\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7055\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5778 - accuracy: 0.7001\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.7024\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5766 - accuracy: 0.7017\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7058\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5746 - accuracy: 0.7059\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5737 - accuracy: 0.7057\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.7059\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5719 - accuracy: 0.7057\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.7079\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.7024\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.7058\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7071\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7071\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.7066\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.7058\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7050\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7098\n",
      "52/52 [==============================] - 0s 843us/step - loss: 0.5764 - accuracy: 0.7077\n",
      "--- Starting trial: run-44\n",
      "{'num_units': 120, 'dropout': 0.1, 'optimizer': 'sgd', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6186 - accuracy: 0.6712\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.6857\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5824 - accuracy: 0.6919\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.6995\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7004\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7035\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.7027\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7041\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7061\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.7042\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7019\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.7049\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7059\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7030\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7084\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7015\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7075\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7035\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7062\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7088\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.7071\n",
      "--- Starting trial: run-45\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5929 - accuracy: 0.6877\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5823 - accuracy: 0.6917\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5767 - accuracy: 0.6958\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7057\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7032\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7085\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7055\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7039\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7062\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7075\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7085\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7107\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7083\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5650 - accuracy: 0.7081\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7110\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7086\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7066\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7112\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7125\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7107\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.7120\n",
      "--- Starting trial: run-46\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6887\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.7001\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7000\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7057\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5695 - accuracy: 0.7090\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5688 - accuracy: 0.7081\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7090\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5672 - accuracy: 0.7096\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5655 - accuracy: 0.7118\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5635 - accuracy: 0.7096\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5631 - accuracy: 0.7123\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7119\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7151\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7159\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5596 - accuracy: 0.7118\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5563 - accuracy: 0.7181\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7203\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7199\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7178\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7185\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.7029\n",
      "--- Starting trial: run-47\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'adam', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5847 - accuracy: 0.6921\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5756 - accuracy: 0.7019\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5740 - accuracy: 0.7071\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7009\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7042\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7075\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7074\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7085\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7098\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7146\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7114\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7097\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7173\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7169\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7150\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7167\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7167\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5497 - accuracy: 0.7186\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7208\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7243\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5817 - accuracy: 0.7059\n",
      "--- Starting trial: run-48\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.5954 - accuracy: 0.6892\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5782 - accuracy: 0.6966\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5777 - accuracy: 0.6987\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.7027\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5720 - accuracy: 0.7013\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5721 - accuracy: 0.7057\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7063\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7074\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7089\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.7064\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7042\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7057\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7092\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7063\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7076\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.7092\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.7072\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.7061\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7068\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7120\n",
      "52/52 [==============================] - 0s 823us/step - loss: 0.5770 - accuracy: 0.7095\n",
      "--- Starting trial: run-49\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5856 - accuracy: 0.6982\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.6993\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7024\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7075\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7031\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7081\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7057\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7089\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7074\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7102\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7127\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7143\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7143\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7150\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7137\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7167\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7147\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7191\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7140\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7184\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5805 - accuracy: 0.7095\n",
      "--- Starting trial: run-50\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'rmsprop', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5882 - accuracy: 0.6874\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5774 - accuracy: 0.6998\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5727 - accuracy: 0.7017\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5737 - accuracy: 0.7023\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5716 - accuracy: 0.7067\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5702 - accuracy: 0.7072\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5693 - accuracy: 0.7076\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7116\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5672 - accuracy: 0.7101\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5639 - accuracy: 0.7114\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5627 - accuracy: 0.7146\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5629 - accuracy: 0.7195: 0s - loss: 0.555\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5602 - accuracy: 0.7146\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5587 - accuracy: 0.7159\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5584 - accuracy: 0.7158\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5569 - accuracy: 0.7181\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5532 - accuracy: 0.7195\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5541 - accuracy: 0.7216\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5511 - accuracy: 0.7240\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7291\n",
      "52/52 [==============================] - 0s 863us/step - loss: 0.5888 - accuracy: 0.6999\n",
      "--- Starting trial: run-51\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 1}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.6154 - accuracy: 0.6688\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.6882\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5839 - accuracy: 0.6957\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5817 - accuracy: 0.6957\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 0.6991\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.6996\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.6971\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.7009\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7052\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.6992\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.7022\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5757 - accuracy: 0.7022\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5736 - accuracy: 0.7035\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5761 - accuracy: 0.7008\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5739 - accuracy: 0.7026\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.7049\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.7045\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.7040\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5731 - accuracy: 0.7039\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.7019\n",
      "52/52 [==============================] - 0s 824us/step - loss: 0.5789 - accuracy: 0.7071\n",
      "--- Starting trial: run-52\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 2}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6119 - accuracy: 0.6746\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.6901\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5833 - accuracy: 0.6984\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.6962\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.6982\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7001\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.7013\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5757 - accuracy: 0.7028\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5752 - accuracy: 0.7046\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7046\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7052\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.7045\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.7052\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7059\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.7037\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7067\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7070\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7032\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.7041\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5703 - accuracy: 0.7058\n",
      "52/52 [==============================] - 0s 882us/step - loss: 0.5767 - accuracy: 0.7017\n",
      "--- Starting trial: run-53\n",
      "{'num_units': 120, 'dropout': 0.2, 'optimizer': 'sgd', 'num_layers': 3}\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6164 - accuracy: 0.6639\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.6833\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.6910\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.6963\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.6983\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.6976\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.6991\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.6998\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.7011\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7030\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7001\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7020\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7070\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7050\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7052\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7049\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.7072\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7093\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7064\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7045\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5773 - accuracy: 0.7071\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "        for num_layers in HP_NUM_LAYERS.domain.values:\n",
    "          hparams = {\n",
    "              HP_NUM_UNITS: num_units,\n",
    "              HP_DROPOUT: dropout_rate,\n",
    "              HP_OPTIMIZER: optimizer,\n",
    "              HP_NUM_LAYERS: num_layers,\n",
    "          }\n",
    "          run_name = \"run-%d\" % session_num\n",
    "          print('--- Starting trial: %s' % run_name)\n",
    "          print({h.name: hparams[h] for h in hparams})\n",
    "          run('logs/hparam_tuning/' + run_name, hparams)\n",
    "          session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "984bce2b-7b61-4066-9606-385dca9e2c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13816), started 3 days, 19:02:53 ago. (Use '!kill 13816' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-995be98f07c7a76e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-995be98f07c7a76e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning --host localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c2c2d-1bbf-4bde-b29c-45dfd41cea5d",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23360e4f-3c0a-4f73-84e2-d68e399a613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: DNN \n",
      "Accuracy: 0.716183602809906\n",
      "Parameters: dict_values([80, 0.2, 'rmsprop', 1])\n"
     ]
    }
   ],
   "source": [
    "print('Best Model:', best_model['name'], '\\nAccuracy:', best_model['acc']) \n",
    "\n",
    "if (best_model['name'] == 'DNN'):\n",
    "    print('Parameters:', best_model['params'].values())\n",
    "else:\n",
    "    print('Parameters:', best_model['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f4b58-610e-4b36-92ea-3157658ce38e",
   "metadata": {},
   "source": [
    "Now, let's test our best model against our validation set and see how it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09da2559-41a9-4e72-a63c-d54680084cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 843us/step - loss: 0.5527 - accuracy: 0.7289\n",
      "Accuracy of best model on validation set: 0.7288647294044495\n"
     ]
    }
   ],
   "source": [
    "prediction = best_model['model'].predict(valid_x)\n",
    "if (best_model['name'] == 'DNN'):\n",
    "    prediction = np.argmax(prediction, axis=1)\n",
    "    _, valid_acc = best_model['model'].evaluate(valid_x, valid_y)\n",
    "else:\n",
    "    valid_acc = accuracy_score(valid_y, prediction)\n",
    "\n",
    "print(\"Accuracy of best model on validation set:\", valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ecffa-b377-48ac-9725-98ffe6c7984b",
   "metadata": {},
   "source": [
    "## Racism Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa634536-41cf-4cbf-9809-b19e9b1cc6b0",
   "metadata": {},
   "source": [
    "Last but not least, let's check out how racist our model is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3bb29c4-f06d-4d07-892d-8151ecb51f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to get different sets of data based on recidivism value\n",
    "def get_diff_dict(column):\n",
    "    predict_df = valid_df.copy(deep=True)   \n",
    "    predict_df[column] = prediction\n",
    "\n",
    "    yes_predict_df = predict_df[predict_df[column] == 1]\n",
    "    yes_valid_df = valid_df[valid_df[column] == 1]\n",
    "\n",
    "    no_predict_df = predict_df[predict_df[column] == 0]\n",
    "    no_valid_df = valid_df[valid_df[column] == 0]\n",
    "\n",
    "    return {'Validation Set': valid_df, 'Prediction Set': predict_df,\n",
    "              'Validation where Recidivism=True': yes_valid_df, 'Prediction where Recidivism=True': yes_predict_df,\n",
    "              'Validation where Recidivism=False': no_valid_df, 'Prediction where Recidivism=False': no_predict_df}\n",
    "    \n",
    "    \n",
    "diff_dict = get_diff_dict('is_recid')\n",
    "diff_values = list(diff_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26174e06-05d8-4519-8632-04a1ccf49ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "i = 1\n",
    "for k, v in diff_dict.items():\n",
    "    ax = fig.add_subplot(3,2,i)\n",
    "    ax.barh(v.sort_values('race')['race'].unique(), v.sort_values('race')['race'].value_counts(sort=False))\n",
    "    ax.set_title(k)\n",
    "    i += 1\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=1.5)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ac5993a-81d5-4f0c-b30b-1f598a9443ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2%}'.format\n",
    "def compare_ethnic_spread(base_df, hyp_df):\n",
    "    base_ethnicity_spread = base_df['race'].value_counts(normalize=True)\n",
    "    hyp_ethnicity_spread = hyp_df['race'].value_counts(normalize=True)\n",
    "\n",
    "    \n",
    "    print(\n",
    "'''          ACTUAL\n",
    "{}\\n--------------------------\n",
    "         PREDICTED\n",
    "{}\\n--------------------------\n",
    "         DIFFERENCE'''.format(base_ethnicity_spread, hyp_ethnicity_spread))\n",
    "    \n",
    "    diff = dict()\n",
    "    for race in hyp_df['race'].unique():\n",
    "        diff[race] = hyp_ethnicity_spread[race] - base_ethnicity_spread[race]\n",
    "        \n",
    "    print(\"\\n\".join(\"{:>17}  {:>6.2%}\".format(k, v) for k, v in diff.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb42aa3d-6782-4a63-a7d7-de6e9ef7ee0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        UNFILTERED\n",
      "\n",
      "          ACTUAL\n",
      "African-American   50.42%\n",
      "Caucasian          34.18%\n",
      "Hispanic            9.06%\n",
      "Other               5.68%\n",
      "Asian               0.42%\n",
      "Native American     0.24%\n",
      "Name: race, dtype: float64\n",
      "--------------------------\n",
      "         PREDICTED\n",
      "African-American   50.42%\n",
      "Caucasian          34.18%\n",
      "Hispanic            9.06%\n",
      "Other               5.68%\n",
      "Asian               0.42%\n",
      "Native American     0.24%\n",
      "Name: race, dtype: float64\n",
      "--------------------------\n",
      "         DIFFERENCE\n",
      " African-American   0.00%\n",
      "        Caucasian   0.00%\n",
      "            Other   0.00%\n",
      "         Hispanic   0.00%\n",
      "            Asian   0.00%\n",
      "  Native American   0.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"        UNFILTERED\\n\")\n",
    "compare_ethnic_spread(diff_values[0], diff_values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bffef329-15df-432b-bfe5-f97e07b8be11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    RECIDIVISM == TRUE\n",
      "\n",
      "          ACTUAL\n",
      "African-American   61.44%\n",
      "Caucasian          27.75%\n",
      "Hispanic            5.59%\n",
      "Other               4.50%\n",
      "Asian               0.36%\n",
      "Native American     0.36%\n",
      "Name: race, dtype: float64\n",
      "--------------------------\n",
      "         PREDICTED\n",
      "African-American   71.38%\n",
      "Caucasian          19.08%\n",
      "Hispanic            5.92%\n",
      "Other               2.96%\n",
      "Asian               0.33%\n",
      "Native American     0.33%\n",
      "Name: race, dtype: float64\n",
      "--------------------------\n",
      "         DIFFERENCE\n",
      " African-American   9.94%\n",
      "        Caucasian  -8.67%\n",
      "            Other  -1.54%\n",
      "         Hispanic   0.34%\n",
      "            Asian  -0.03%\n",
      "  Native American  -0.03%\n"
     ]
    }
   ],
   "source": [
    "print(\"    RECIDIVISM == TRUE\\n\")\n",
    "compare_ethnic_spread(diff_values[2], diff_values[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d64080a9-5b47-48fb-8f42-af085acb25cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RECIDIVISM == FALSE\n",
      "\n",
      "          ACTUAL\n",
      "African-American   44.87%\n",
      "Caucasian          37.42%\n",
      "Hispanic           10.81%\n",
      "Other               6.27%\n",
      "Asian               0.45%\n",
      "Native American     0.18%\n",
      "Name: race, dtype: float64\n",
      "--------------------------\n",
      "         PREDICTED\n",
      "African-American   45.71%\n",
      "Caucasian          37.57%\n",
      "Hispanic            9.76%\n",
      "Other               6.29%\n",
      "Asian               0.44%\n",
      "Native American     0.22%\n",
      "Name: race, dtype: float64\n",
      "--------------------------\n",
      "         DIFFERENCE\n",
      " African-American   0.84%\n",
      "        Caucasian   0.15%\n",
      "            Other   0.02%\n",
      "         Hispanic  -1.05%\n",
      "            Asian  -0.01%\n",
      "  Native American   0.04%\n"
     ]
    }
   ],
   "source": [
    "print(\"   RECIDIVISM == FALSE\\n\")\n",
    "compare_ethnic_spread(diff_values[4], diff_values[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
